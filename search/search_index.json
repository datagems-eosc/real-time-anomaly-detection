{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Real-Time Anomaly Detection","text":"<p>This is the documentation site for the Real-Time Anomaly Detection service. The service is part of the wider DataGEMS platform.</p> <p>The Real-Time Anomaly Detection service is designed to monitor meteorological stations and distinguish between genuine device failures and extreme weather events using a dual-verification strategy combining temporal and spatial analysis.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Dual-Verification Strategy: Combines temporal self-checks with spatial neighbor verification to minimize false alarms</li> <li>Multi-Method Support: Includes ARIMA, Z-Score, MAD, IQR, Isolation Forest, STL, and LOF detection methods</li> <li>Real-Time Processing: Streaming architecture with 10-minute data ingestion intervals</li> <li>Spatial Intelligence: Automatically detects and correlates anomalies across neighboring stations within 100km radius</li> <li>Scalable Architecture: Supports both SQLite for standalone deployment and TimescaleDB for enterprise scale</li> <li>Interactive Visualization: Generates station network maps showing spatial relationships</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<p>The Real-Time Anomaly Detection service works through a two-step verification process:</p>"},{"location":"#step-1-temporal-detection","title":"Step 1: Temporal Detection","text":"<p>Analyzes each station's current readings against its own historical data using time series methods (e.g., ARIMA) to detect deviations from expected patterns.</p>"},{"location":"#step-2-spatial-verification","title":"Step 2: Spatial Verification","text":"<p>Compares the suspect station's behavior with neighboring stations to determine if the anomaly is:</p> <ul> <li>Weather Event: Neighboring stations show similar patterns (high correlation &gt; 0.6)</li> <li>Device Failure: Only this station is anomalous (low correlation &lt; 0.3)</li> </ul>"},{"location":"#data-flow","title":"Data Flow","text":"<pre><code>graph LR\n    A[NOA API] --&gt;|Every 10 min| B[Data Collector]\n    B --&gt;|Store| C[SQLite/TimescaleDB]\n    C --&gt;|Query Window| D[Anomaly Detector]\n    D --&gt;|Temporal Check| E{Anomalous?}\n    E --&gt;|No| F[Normal]\n    E --&gt;|Yes| G[Spatial Verify]\n    G --&gt;|High Corr| H[Weather Event]\n    G --&gt;|Low Corr| I[Device Failure]</code></pre>"},{"location":"#target-deployment","title":"Target Deployment","text":"<p>The service currently monitors 14 meteorological stations operated by the National Observatory of Athens (NOA), with data updates every 10 minutes from the NOA DataGEMS Feed.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install dependencies\npip install -r requirements.txt\n\n# Start data collection\n./manage_collector.sh start\n\n# Run detection\npython anomaly_detector.py \\\n  --end \"NOW\" \\\n  --window 6 \\\n  --temporal-method arima \\\n  --spatial-verify\n</code></pre> <p>For detailed installation instructions, see the Installation Guide.</p>"},{"location":"#data-format","title":"Data Format","text":"<p>The service processes five core meteorological variables:</p> Variable Description Unit <code>temp_out</code> Outdoor Temperature \u00b0C <code>out_hum</code> Outdoor Humidity % <code>wind_speed</code> Wind Speed km/h <code>bar</code> Barometric Pressure hPa <code>rain</code> Rainfall Rate mm"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>The system follows a pull-based streaming architecture:</p> <ul> <li>Collector: Background daemon fetching data from NOA API every 10 minutes</li> <li>Database: SQLite for standalone or TimescaleDB for enterprise deployment</li> <li>Detector: On-demand or scheduled analysis using sliding window mechanism</li> <li>Reporter: Console and JSON output with detailed anomaly classifications</li> </ul> <p>For more details, see the Architecture documentation.</p>"},{"location":"#support","title":"Support","text":"<p>For questions, issues, or contributions:</p> <ul> <li>GitHub Issues: Report a bug or request a feature</li> <li>Documentation: Browse this documentation site</li> <li>FAQ: Check the Frequently Asked Questions</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-the-real-time-anomaly-detection-system","title":"What is the Real-Time Anomaly Detection system?","text":"<p>It's a tool that monitors weather stations and automatically distinguishes between genuine equipment failures and extreme weather events using temporal and spatial analysis.</p>"},{"location":"faq/#who-is-this-system-for","title":"Who is this system for?","text":"<ul> <li>Weather station operators</li> <li>Meteorological agencies</li> <li>Research institutions</li> <li>Infrastructure monitoring teams</li> </ul>"},{"location":"faq/#what-makes-this-different-from-traditional-anomaly-detection","title":"What makes this different from traditional anomaly detection?","text":"<p>Traditional systems can't tell the difference between a broken sensor and extreme weather - they just flag everything as anomalous. Our dual-verification strategy uses neighbor stations to classify anomalies correctly.</p>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"faq/#what-are-the-system-requirements","title":"What are the system requirements?","text":"<ul> <li>Python 3.8 or higher</li> <li>512MB RAM (minimum), 2GB recommended</li> <li>1GB disk space</li> <li>Linux or macOS (Windows may work but is untested)</li> </ul>"},{"location":"faq/#do-i-need-a-database-server","title":"Do I need a database server?","text":"<p>No. By default, the system uses SQLite which is embedded in Python. For enterprise deployments (&gt;100 stations), you can optionally use TimescaleDB.</p>"},{"location":"faq/#how-do-i-install-it","title":"How do I install it?","text":"<pre><code>git clone https://github.com/datagems-eosc/real-time-anomaly-detection.git\ncd real-time-anomaly-detection/stream_detection\npip install -r requirements.txt\n./manage_collector.sh start\n</code></pre> <p>See Installation Guide for details.</p>"},{"location":"faq/#can-i-run-this-on-windows","title":"Can I run this on Windows?","text":"<p>The system is primarily designed for Linux/macOS. Windows support is not officially tested, but you can try:</p> <ul> <li>Use WSL (Windows Subsystem for Linux)</li> <li>Run in Docker</li> <li>Use a Linux VM</li> </ul>"},{"location":"faq/#detection-configuration","title":"Detection &amp; Configuration","text":""},{"location":"faq/#what-detection-methods-are-supported","title":"What detection methods are supported?","text":"<p>Seven temporal methods:</p> <ul> <li>ARIMA (recommended) - Best accuracy</li> <li>3-Sigma - Fastest</li> <li>MAD - Most robust</li> <li>IQR - Simple baseline</li> <li>Isolation Forest - ML-based</li> <li>STL - For seasonal data</li> <li>LOF - Density-based</li> </ul> <p>See Detection Methods for comparisons.</p>"},{"location":"faq/#which-method-should-i-use","title":"Which method should I use?","text":"<p>For production: ARIMA with spatial verification</p> <pre><code>python anomaly_detector.py --end \"NOW\" --temporal-method arima --spatial-verify\n</code></pre> <p>For testing: 3-Sigma (much faster)</p> <pre><code>python anomaly_detector.py --end \"NOW\" --temporal-method 3sigma\n</code></pre>"},{"location":"faq/#how-do-i-tune-detection-sensitivity","title":"How do I tune detection sensitivity?","text":"<p>Adjust thresholds based on your needs:</p> <p>More sensitive (more detections): <pre><code>--temporal-threshold 2.5  # Lower = more sensitive\n--correlation-threshold-high 0.7  # Higher = stricter weather criteria\n</code></pre></p> <p>Less sensitive (fewer detections): <pre><code>--temporal-threshold 3.5  # Higher = less sensitive\n--correlation-threshold-high 0.5  # Lower = more lenient weather criteria\n</code></pre></p>"},{"location":"faq/#what-is-spatial-verification","title":"What is spatial verification?","text":"<p>It compares the suspect station with nearby neighbors to determine if the anomaly is:</p> <ul> <li>Weather event: Neighbors show similar patterns (correlation &gt; 0.6)</li> <li>Device failure: Only this station is anomalous (correlation &lt; 0.3)</li> </ul> <p>Always use <code>--spatial-verify</code> in production to reduce false positives by ~80%.</p>"},{"location":"faq/#how-does-the-system-handle-missing-data","title":"How does the system handle missing data?","text":"<ul> <li>Temporal detection: Skips missing points, requires minimum data density</li> <li>Spatial verification: Uses linear interpolation to fill small gaps (&lt; 3 consecutive points)</li> </ul>"},{"location":"faq/#what-if-a-station-has-no-neighbors","title":"What if a station has no neighbors?","text":"<p>The system skips spatial verification for that station and marks anomalies as \"Suspected\" (requiring manual review).</p>"},{"location":"faq/#performance-scalability","title":"Performance &amp; Scalability","text":""},{"location":"faq/#how-fast-is-the-detection","title":"How fast is the detection?","text":"Method Time (14 stations) Time (100 stations) 3-Sigma ~0.1 seconds ~0.7 seconds ARIMA ~2 seconds ~15 seconds Isolation Forest ~1 second ~8 seconds"},{"location":"faq/#how-much-data-does-the-system-store","title":"How much data does the system store?","text":"<p>Approximately 10MB per month for 14 stations with 10-minute intervals using SQLite.</p> <p>With TimescaleDB compression: ~3MB per month.</p>"},{"location":"faq/#can-this-scale-to-1000-stations","title":"Can this scale to 1000 stations?","text":"<p>Yes, but you'll need:</p> <ol> <li>Switch to TimescaleDB instead of SQLite</li> <li>Use parallel processing (future feature)</li> <li>Consider distributed deployment with multiple detection workers</li> </ol> <p>See Database Options for migration guide.</p>"},{"location":"faq/#how-much-memory-does-it-use","title":"How much memory does it use?","text":"<ul> <li>Collector: ~50MB</li> <li>Detector (6-hour window): ~200MB</li> <li>Detector (24-hour window): ~500MB</li> </ul> <p>Memory usage is constant regardless of total database size thanks to the sliding window mechanism.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#why-am-i-getting-insufficient-data-errors","title":"Why am I getting \"Insufficient data\" errors?","text":"<p>The detector requires at least:</p> <ul> <li>1 hour of data for simple methods (3-sigma, MAD, IQR)</li> <li>6 hours for ARIMA (36 data points)</li> <li>24 hours for STL (seasonal decomposition)</li> </ul> <p>Solution: Wait for the collector to accumulate more data, or reduce <code>--window</code> size.</p>"},{"location":"faq/#why-are-there-so-many-false-positives","title":"Why are there so many false positives?","text":"<p>Most likely you're not using spatial verification. Run with:</p> <pre><code>python anomaly_detector.py --end \"NOW\" --spatial-verify\n</code></pre> <p>This reduces false positives by ~80%.</p>"},{"location":"faq/#why-does-mad-report-everything-as-anomalous","title":"Why does MAD report everything as anomalous?","text":"<p>MAD is very sensitive to stable data. If your baseline is flat (e.g., barometric pressure), MAD will flag small changes.</p> <p>Solution: Use ARIMA or 3-Sigma for variables with stable baselines.</p>"},{"location":"faq/#the-collector-stopped-working-how-do-i-restart-it","title":"The collector stopped working. How do I restart it?","text":"<pre><code># Check status\n./manage_collector.sh status\n\n# Restart\n./manage_collector.sh restart\n\n# Check logs\ntail -f streaming_collector.log\n</code></pre>"},{"location":"faq/#how-do-i-check-if-data-collection-is-working","title":"How do I check if data collection is working?","text":"<pre><code># Check database\nsqlite3 weather_stream.db \"SELECT COUNT(*) FROM observations;\"\n\n# Check recent data\nsqlite3 weather_stream.db \"SELECT MAX(time), COUNT(*) FROM observations WHERE time &gt; datetime('now', '-1 hour');\"\n</code></pre> <p>Expected: ~14 new records every 10 minutes (one per station).</p>"},{"location":"faq/#detection-is-too-slow-how-do-i-speed-it-up","title":"Detection is too slow. How do I speed it up?","text":"<ol> <li>Use faster method: Switch from ARIMA to 3-Sigma</li> <li>Reduce window size: Use <code>--window 3</code> instead of 6</li> <li>Analyze fewer variables: Use <code>--variables \"temp_out\"</code> instead of all</li> <li>Optimize database: Run <code>VACUUM</code> on SQLite</li> </ol>"},{"location":"faq/#data-integration","title":"Data &amp; Integration","text":""},{"location":"faq/#where-does-the-data-come-from","title":"Where does the data come from?","text":"<p>National Observatory of Athens (NOA) via their DataGEMS GeoJSON feed: https://stratus.meteo.noa.gr/data/stations/latestValues_Datagems.geojson</p> <p>Updated every 10 minutes.</p>"},{"location":"faq/#can-i-use-my-own-data-source","title":"Can I use my own data source?","text":"<p>Yes. Edit <code>streaming_collector_sqlite.py</code> to:</p> <ol> <li>Change <code>API_URL</code> to your endpoint</li> <li>Modify <code>parse_geojson()</code> to match your data format</li> <li>Restart the collector</li> </ol>"},{"location":"faq/#how-do-i-export-data-for-analysis","title":"How do I export data for analysis?","text":"<pre><code># Export to CSV\nsqlite3 weather_stream.db &lt;&lt;EOF\n.headers on\n.mode csv\n.output data_export.csv\nSELECT * FROM observations WHERE time &gt; '2025-11-01';\nEOF\n</code></pre> <p>Or use the built-in tool:</p> <pre><code>python view_data.py --start \"2025-11-01\" --end \"2025-11-30\" --output export.csv\n</code></pre>"},{"location":"faq/#can-i-integrate-this-with-grafanaprometheus","title":"Can I integrate this with Grafana/Prometheus?","text":"<p>Yes! See API Examples for Prometheus exporter code.</p> <p>Future releases will include native exporters.</p>"},{"location":"faq/#how-do-i-get-json-output","title":"How do I get JSON output?","text":"<pre><code>python anomaly_detector.py --end \"NOW\" --spatial-verify --save report.json\n</code></pre> <p>See Response Format for JSON schema.</p>"},{"location":"faq/#best-practices","title":"Best Practices","text":""},{"location":"faq/#how-often-should-i-run-detection","title":"How often should I run detection?","text":"<p>Recommended: Hourly</p> <pre><code># Add to cron\n0 * * * * cd /path/to/stream_detection &amp;&amp; python anomaly_detector.py --end \"NOW\" --spatial-verify\n</code></pre> <p>More frequent (every 30 min) is fine, but provides diminishing returns since weather changes slowly.</p>"},{"location":"faq/#should-i-always-use-spatial-verification","title":"Should I always use spatial verification?","text":"<p>Yes, unless:</p> <ul> <li>You're just testing</li> <li>You only have isolated stations (no neighbors)</li> <li>You want to analyze historical data without neighbor context</li> </ul> <p>Spatial verification is the core innovation of this system - don't skip it!</p>"},{"location":"faq/#what-variables-should-i-monitor","title":"What variables should I monitor?","text":"<p>Priority 1 (most reliable for failure detection): - <code>temp_out</code> (temperature) - <code>bar</code> (barometric pressure)</p> <p>Priority 2 (useful but noisier): - <code>out_hum</code> (humidity) - <code>rain</code> (rainfall)</p> <p>Priority 3 (very noisy, many false positives): - <code>wind_speed</code> (highly variable)</p> <p>Start with temp and pressure, add others as needed.</p>"},{"location":"faq/#how-do-i-reduce-false-alarms","title":"How do I reduce false alarms?","text":"<ol> <li>Enable spatial verification (most important!)</li> <li>Use ARIMA instead of 3-Sigma/MAD</li> <li>Increase thresholds slightly</li> <li>Exclude wind_speed from analysis (too noisy)</li> <li>Tune correlation thresholds based on your terrain</li> </ol>"},{"location":"faq/#advanced-topics","title":"Advanced Topics","text":""},{"location":"faq/#can-i-add-custom-detection-methods","title":"Can I add custom detection methods?","text":"<p>Yes. Implement the <code>TemporalDetector</code> interface:</p> <pre><code>class MyCustomDetector(TemporalDetector):\n    def is_anomalous(self, station_data, variable):\n        # Your logic here\n        return True  # if anomalous\n</code></pre> <p>See the source code for examples.</p>"},{"location":"faq/#can-i-adjust-parameters-per-variable","title":"Can I adjust parameters per variable?","text":"<p>Currently, parameters are global. Per-variable configuration is a planned feature.</p> <p>Workaround: Run detection separately for each variable:</p> <pre><code>python anomaly_detector.py --variables \"temp_out\" --temporal-threshold 3.0\npython anomaly_detector.py --variables \"wind_speed\" --temporal-threshold 4.0\n</code></pre>"},{"location":"faq/#how-do-i-migrate-from-sqlite-to-timescaledb","title":"How do I migrate from SQLite to TimescaleDB?","text":"<p>See the complete guide: Database Migration</p> <p>Summary: 1. Export SQLite to CSV 2. Create TimescaleDB hypertable 3. Import CSV 4. Update connection string 5. Restart services</p>"},{"location":"faq/#can-i-run-this-as-a-rest-api","title":"Can I run this as a REST API?","text":"<p>Not yet, but the system is designed to support it. A future release will include a Flask/FastAPI wrapper.</p> <p>Current workaround: Call via subprocess and parse JSON output.</p>"},{"location":"faq/#support-contribution","title":"Support &amp; Contribution","text":""},{"location":"faq/#where-can-i-report-bugs","title":"Where can I report bugs?","text":"<p>GitHub Issues: https://github.com/datagems-eosc/real-time-anomaly-detection/issues</p>"},{"location":"faq/#how-do-i-contribute","title":"How do I contribute?","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Submit a pull request</li> </ol> <p>See CONTRIBUTING.md (coming soon) for guidelines.</p>"},{"location":"faq/#is-there-a-user-community","title":"Is there a user community?","text":"<p>We're building one! Join the discussion:</p> <ul> <li>GitHub Discussions (coming soon)</li> <li>Mailing list (coming soon)</li> </ul>"},{"location":"faq/#can-i-use-this-for-commercial-purposes","title":"Can I use this for commercial purposes?","text":"<p>Yes, the system is open-source under [LICENSE]. Check the license file for details.</p>"},{"location":"faq/#still-have-questions","title":"Still Have Questions?","text":"<ul> <li>Read the Overview for system introduction</li> <li>Check API Documentation for parameter details</li> <li>Browse Code Examples for common use cases</li> <li>Review Detection Methods for algorithm details</li> </ul> <p>If your question isn't answered, open a GitHub issue or contact the development team.</p>"},{"location":"license/","title":"License","text":"<p>This project is funded by the European Union under the Horizon Europe Research and Innovation Programme via Grant Agreement No 101188416.</p>"},{"location":"license/#datagems-project","title":"DataGEMS Project","text":"<p>The Real-Time Anomaly Detection system is part of the wider DataGEMS (Data-driven Gems of the EOSC) platform, which aims to enhance the European Open Science Cloud (EOSC) with advanced data profiling and analysis services.</p>"},{"location":"license/#copyright","title":"Copyright","text":"<p>\u00a9 2025 DataGEMS Consortium</p>"},{"location":"license/#software-license","title":"Software License","text":"<p>[To be determined by the project - typical options include Apache 2.0, MIT, or GPL]</p> <p>Please refer to the LICENSE file in the repository root for the complete license text.</p>"},{"location":"license/#citation","title":"Citation","text":"<p>If you use this system in your research, please cite:</p> <pre><code>DataGEMS Consortium (2025). Real-Time Anomaly Detection for Meteorological Stations.\nHorizon Europe Project, Grant Agreement No 101188416.\nAvailable at: https://github.com/datagems-eosc/real-time-anomaly-detection\n</code></pre>"},{"location":"license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>This software uses the following open-source packages:</p> <ul> <li>Python: PSF License</li> <li>Pandas: BSD 3-Clause License</li> <li>NumPy: BSD License</li> <li>scikit-learn: BSD 3-Clause License</li> <li>statsmodels: BSD 3-Clause License</li> <li>Folium: MIT License</li> <li>SQLite: Public Domain</li> <li>psycopg2: LGPL License (optional, for PostgreSQL/TimescaleDB)</li> </ul> <p>See <code>requirements.txt</code> for the complete list of dependencies.</p>"},{"location":"license/#data-attribution","title":"Data Attribution","text":"<p>Weather data is provided by:</p> <p>National Observatory of Athens (NOA) https://www.noa.gr</p> <p>Data is accessed via the NOA DataGEMS API under the terms of the DataGEMS project agreement.</p>"},{"location":"license/#contact","title":"Contact","text":"<p>For licensing inquiries:</p> <ul> <li>Project Website: https://datagems-eosc.eu</li> <li>Email: contact@datagems-eosc.eu</li> <li>GitHub: https://github.com/datagems-eosc</li> </ul>"},{"location":"license/#acknowledgments","title":"Acknowledgments","text":"<p>This project has received funding from the European Union's Horizon Europe research and innovation programme under grant agreement No 101188416.</p> <p>Disclaimer: The content of this documentation reflects only the authors' view. The European Commission is not responsible for any use that may be made of the information it contains.</p>"},{"location":"api/examples/","title":"Code Examples","text":""},{"location":"api/examples/#basic-usage-examples","title":"Basic Usage Examples","text":""},{"location":"api/examples/#example-1-real-time-detection","title":"Example 1: Real-Time Detection","text":"<p>Detect anomalies at the current time with default settings:</p> <pre><code>python anomaly_detector.py --end \"NOW\" --spatial-verify\n</code></pre> <p>Output:</p> <pre><code>Total Stations: 14\nAnomalous Stations: 0\nNormal Stations: 14\n\nAnomaly Breakdown:\n  \ud83d\udd34 Device Failures: 0\n  \ud83c\udf27\ufe0f Weather Events: 0\n  \u26a0\ufe0f Suspected: 0\n</code></pre>"},{"location":"api/examples/#example-2-historical-analysis","title":"Example 2: Historical Analysis","text":"<p>Analyze a specific historical timestamp:</p> <pre><code>python anomaly_detector.py \\\n  --end \"2025-11-22 17:00:00\" \\\n  --window 6 \\\n  --temporal-method arima \\\n  --spatial-verify\n</code></pre> <p>Use Case: Investigate why an alert was missed or validate detection performance.</p>"},{"location":"api/examples/#example-3-method-comparison","title":"Example 3: Method Comparison","text":"<p>Compare different detection methods on the same data:</p> <pre><code># ARIMA (best accuracy)\npython anomaly_detector.py --end \"2025-11-22 17:00:00\" --temporal-method arima --spatial-verify --save report_arima.json\n\n# 3-Sigma (fastest)\npython anomaly_detector.py --end \"2025-11-22 17:00:00\" --temporal-method 3sigma --spatial-verify --save report_3sigma.json\n\n# MAD (most robust)\npython anomaly_detector.py --end \"2025-11-22 17:00:00\" --temporal-method mad --spatial-verify --save report_mad.json\n</code></pre> <p>Then compare results:</p> <pre><code>echo \"ARIMA:\"\njq '.summary' report_arima.json\n\necho \"3-Sigma:\"\njq '.summary' report_3sigma.json\n\necho \"MAD:\"\njq '.summary' report_mad.json\n</code></pre>"},{"location":"api/examples/#example-4-single-variable-analysis","title":"Example 4: Single Variable Analysis","text":"<p>Only analyze temperature:</p> <pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --variables \"temp_out\" \\\n  --temporal-method arima \\\n  --spatial-verify\n</code></pre> <p>Use Case: Faster execution when you only care about specific variables.</p>"},{"location":"api/examples/#example-5-without-spatial-verification","title":"Example 5: Without Spatial Verification","text":"<p>Quick temporal check without neighbor comparison:</p> <pre><code>python anomaly_detector.py --end \"NOW\" --temporal-method 3sigma\n</code></pre> <p>Warning: Higher false positive rate. Only use for testing.</p>"},{"location":"api/examples/#advanced-examples","title":"Advanced Examples","text":""},{"location":"api/examples/#example-6-custom-thresholds","title":"Example 6: Custom Thresholds","text":"<p>Fine-tune detection sensitivity:</p> <pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --temporal-method 3sigma \\\n  --temporal-threshold 2.5 \\\n  --spatial-verify \\\n  --correlation-threshold-high 0.7 \\\n  --correlation-threshold-low 0.2\n</code></pre> <p>Effect:</p> <ul> <li>Lower temporal threshold (2.5 vs 3.0): More sensitive \u2192 more detections</li> <li>Higher correlation threshold (0.7 vs 0.6): Stricter weather event criteria</li> </ul>"},{"location":"api/examples/#example-7-wider-neighbor-radius","title":"Example 7: Wider Neighbor Radius","text":"<p>Expand spatial verification to 150km:</p> <pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --spatial-verify \\\n  --neighbor-radius 150\n</code></pre> <p>Use Case: Sparse station networks or large-scale weather phenomena.</p>"},{"location":"api/examples/#example-8-verbose-debugging","title":"Example 8: Verbose Debugging","text":"<p>Get detailed execution logs:</p> <pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --spatial-verify \\\n  --verbose\n</code></pre> <p>Output includes:</p> <ul> <li>Database queries</li> <li>Model fitting details</li> <li>Correlation calculations</li> <li>Classification logic</li> </ul>"},{"location":"api/examples/#automation-examples","title":"Automation Examples","text":""},{"location":"api/examples/#example-9-cron-job-hourly-monitoring","title":"Example 9: Cron Job (Hourly Monitoring)","text":"<p>Add to crontab:</p> <pre><code># Edit crontab\ncrontab -e\n\n# Add this line (runs every hour)\n0 * * * * cd /path/to/stream_detection &amp;&amp; /path/to/python anomaly_detector.py --end \"NOW\" --spatial-verify --save /var/log/anomaly_reports/report_$(date +\\%Y\\%m\\%d_\\%H\\%M).json &gt;&gt; /var/log/anomaly_detector.log 2&gt;&amp;1\n</code></pre>"},{"location":"api/examples/#example-10-alert-on-device-failures","title":"Example 10: Alert on Device Failures","text":"<p>Bash script that sends alerts:</p> <pre><code>#!/bin/bash\n# detect_and_alert.sh\n\nREPORT_FILE=\"/tmp/anomaly_report.json\"\n\n# Run detection\npython anomaly_detector.py \\\n  --end \"NOW\" \\\n  --spatial-verify \\\n  --save \"$REPORT_FILE\"\n\n# Check for device failures\nFAILURES=$(jq '.summary.device_failures' \"$REPORT_FILE\")\n\nif [ \"$FAILURES\" -gt 0 ]; then\n    # Extract failure details\n    STATIONS=$(jq -r '.anomalies[] | select(.classification == \"device_failure\") | .station_id' \"$REPORT_FILE\" | tr '\\n' ', ')\n\n    # Send alert (example with email)\n    echo \"Device failures detected at: $STATIONS\" | \\\n        mail -s \"ALERT: Weather Station Failure\" admin@example.com\n\n    # Send alert (example with Slack)\n    curl -X POST -H 'Content-type: application/json' \\\n        --data \"{\\\"text\\\":\\\"\ud83d\udd34 Device failures detected: $STATIONS\\\"}\" \\\n        YOUR_SLACK_WEBHOOK_URL\nfi\n</code></pre> <p>Make executable and add to cron:</p> <pre><code>chmod +x detect_and_alert.sh\n\n# Run every 30 minutes\n*/30 * * * * /path/to/detect_and_alert.sh\n</code></pre>"},{"location":"api/examples/#example-11-batch-historical-analysis","title":"Example 11: Batch Historical Analysis","text":"<p>Analyze multiple historical timestamps:</p> <pre><code>#!/bin/bash\n# batch_analysis.sh\n\nSTART_DATE=\"2025-11-01 00:00:00\"\nEND_DATE=\"2025-11-22 23:00:00\"\nINTERVAL_HOURS=6\n\ncurrent=$(date -d \"$START_DATE\" +%s)\nend=$(date -d \"$END_DATE\" +%s)\n\nwhile [ $current -le $end ]; do\n    timestamp=$(date -d \"@$current\" \"+%Y-%m-%d %H:%M:%S\")\n    echo \"Analyzing $timestamp...\"\n\n    python anomaly_detector.py \\\n        --end \"$timestamp\" \\\n        --window 6 \\\n        --spatial-verify \\\n        --save \"reports/report_${current}.json\"\n\n    current=$((current + INTERVAL_HOURS * 3600))\ndone\n\n# Aggregate results\necho \"Aggregating results...\"\njq -s '[.[] | .anomalies[]] | group_by(.classification) | map({classification: .[0].classification, count: length})' reports/*.json &gt; summary.json\n</code></pre>"},{"location":"api/examples/#example-12-python-integration","title":"Example 12: Python Integration","text":"<p>Use the detector in a Python application:</p> <pre><code>import subprocess\nimport json\nimport sys\n\ndef detect_anomalies(end_time=\"NOW\", method=\"arima\"):\n    \"\"\"\n    Run anomaly detection and return structured results.\n    \"\"\"\n    cmd = [\n        \"python\", \"anomaly_detector.py\",\n        \"--end\", end_time,\n        \"--temporal-method\", method,\n        \"--spatial-verify\",\n        \"--save\", \"/tmp/report.json\"\n    ]\n\n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n\n        # Load JSON report\n        with open('/tmp/report.json', 'r') as f:\n            report = json.load(f)\n\n        return report\n\n    except subprocess.CalledProcessError as e:\n        print(f\"Detection failed: {e.stderr}\", file=sys.stderr)\n        return None\n\n# Usage\nif __name__ == \"__main__\":\n    report = detect_anomalies()\n\n    if report:\n        # Check for device failures\n        if report['summary']['device_failures'] &gt; 0:\n            print(\"\u26a0\ufe0f Device failures detected:\")\n            for anomaly in report['anomalies']:\n                if anomaly['classification'] == 'device_failure':\n                    print(f\"  - {anomaly['station_id']}: {anomaly['variable']} = {anomaly['actual_value']}\")\n        else:\n            print(\"\u2705 All stations operating normally\")\n</code></pre>"},{"location":"api/examples/#example-13-dashboard-integration","title":"Example 13: Dashboard Integration","text":"<p>Export data for real-time dashboard:</p> <pre><code>import json\nimport time\nfrom datetime import datetime\n\ndef export_for_dashboard():\n    \"\"\"\n    Run detection and export to dashboard-friendly format.\n    \"\"\"\n    # Run detection\n    import subprocess\n    subprocess.run([\n        \"python\", \"anomaly_detector.py\",\n        \"--end\", \"NOW\",\n        \"--spatial-verify\",\n        \"--save\", \"/tmp/report.json\"\n    ])\n\n    # Load report\n    with open('/tmp/report.json', 'r') as f:\n        report = json.load(f)\n\n    # Transform for dashboard\n    dashboard_data = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"status\": \"critical\" if report['summary']['device_failures'] &gt; 0 else \"normal\",\n        \"stats\": {\n            \"total\": report['summary']['total_stations'],\n            \"normal\": report['summary']['normal_stations'],\n            \"anomalous\": report['summary']['anomalous_stations'],\n            \"failures\": report['summary']['device_failures']\n        },\n        \"alerts\": [\n            {\n                \"station\": a['station_id'],\n                \"type\": a['classification'],\n                \"value\": a['actual_value'],\n                \"expected\": a['expected_value'],\n                \"severity\": \"high\" if a['classification'] == \"device_failure\" else \"low\"\n            }\n            for a in report['anomalies']\n        ]\n    }\n\n    # Save for dashboard\n    with open('/var/www/dashboard/data/latest.json', 'w') as f:\n        json.dump(dashboard_data, f)\n\n# Run every minute\nwhile True:\n    export_for_dashboard()\n    time.sleep(60)\n</code></pre>"},{"location":"api/examples/#testing-examples","title":"Testing Examples","text":""},{"location":"api/examples/#example-14-test-individual-methods","title":"Example 14: Test Individual Methods","text":"<p>Compare all methods quickly:</p> <pre><code>#!/bin/bash\n# test_all_methods.sh\n\nTIMESTAMP=\"2025-11-22 17:00:00\"\nMETHODS=(\"arima\" \"3sigma\" \"mad\" \"iqr\" \"isolation_forest\" \"stl\" \"lof\")\n\necho \"Method,TotalAnomalies,DeviceFailures,WeatherEvents,ExecutionTime\"\n\nfor method in \"${METHODS[@]}\"; do\n    start=$(date +%s.%N)\n\n    python anomaly_detector.py \\\n        --end \"$TIMESTAMP\" \\\n        --temporal-method \"$method\" \\\n        --spatial-verify \\\n        --save \"/tmp/test_${method}.json\" &gt; /dev/null 2&gt;&amp;1\n\n    end=$(date +%s.%N)\n    runtime=$(echo \"$end - $start\" | bc)\n\n    total=$(jq '.summary.anomalous_stations' \"/tmp/test_${method}.json\")\n    failures=$(jq '.summary.device_failures' \"/tmp/test_${method}.json\")\n    weather=$(jq '.summary.weather_events' \"/tmp/test_${method}.json\")\n\n    echo \"$method,$total,$failures,$weather,$runtime\"\ndone\n</code></pre>"},{"location":"api/examples/#example-15-validate-detection-accuracy","title":"Example 15: Validate Detection Accuracy","text":"<p>Test with known anomalies:</p> <pre><code>import json\nfrom datetime import datetime, timedelta\n\n# Known anomalies (from manual inspection)\nKNOWN_ANOMALIES = {\n    \"2025-11-15 14:00:00\": {\n        \"station\": \"pelion\",\n        \"type\": \"device_failure\",\n        \"variable\": \"temp_out\"\n    },\n    \"2025-11-20 08:00:00\": {\n        \"station\": \"uth_volos\",\n        \"type\": \"weather_event\",\n        \"variable\": \"temp_out\"\n    }\n}\n\ndef validate_detection():\n    \"\"\"\n    Test detection against known anomalies.\n    \"\"\"\n    true_positives = 0\n    false_positives = 0\n    false_negatives = 0\n\n    for timestamp, expected in KNOWN_ANOMALIES.items():\n        # Run detection\n        subprocess.run([\n            \"python\", \"anomaly_detector.py\",\n            \"--end\", timestamp,\n            \"--spatial-verify\",\n            \"--save\", \"/tmp/validation.json\"\n        ], capture_output=True)\n\n        # Load results\n        with open('/tmp/validation.json', 'r') as f:\n            report = json.load(f)\n\n        # Check if detected\n        detected = False\n        for anomaly in report['anomalies']:\n            if (anomaly['station_id'] == expected['station'] and\n                anomaly['variable'] == expected['variable']):\n                detected = True\n\n                # Check classification\n                if anomaly['classification'] == expected['type']:\n                    true_positives += 1\n                else:\n                    false_positives += 1\n                break\n\n        if not detected:\n            false_negatives += 1\n\n    # Calculate metrics\n    precision = true_positives / (true_positives + false_positives)\n    recall = true_positives / (true_positives + false_negatives)\n    f1 = 2 * (precision * recall) / (precision + recall)\n\n    print(f\"Precision: {precision:.2%}\")\n    print(f\"Recall: {recall:.2%}\")\n    print(f\"F1 Score: {f1:.2%}\")\n\nif __name__ == \"__main__\":\n    validate_detection()\n</code></pre>"},{"location":"api/examples/#performance-examples","title":"Performance Examples","text":""},{"location":"api/examples/#example-16-benchmark-methods","title":"Example 16: Benchmark Methods","text":"<p>Compare execution times:</p> <pre><code>#!/bin/bash\n# benchmark.sh\n\necho \"Benchmarking detection methods...\"\n\nfor method in arima 3sigma mad iqr; do\n    echo \"Testing $method...\"\n    time python anomaly_detector.py \\\n        --end \"NOW\" \\\n        --temporal-method \"$method\" \\\n        --spatial-verify \\\n        &gt; /dev/null 2&gt;&amp;1\ndone\n</code></pre> <p>Typical results:</p> <pre><code>Testing arima...\nreal    0m2.345s\n\nTesting 3sigma...\nreal    0m0.123s\n\nTesting mad...\nreal    0m0.156s\n\nTesting iqr...\nreal    0m0.134s\n</code></pre>"},{"location":"api/examples/#example-17-database-performance","title":"Example 17: Database Performance","text":"<p>Test query performance with different window sizes:</p> <pre><code>import subprocess\nimport time\n\nwindow_sizes = [1, 6, 12, 24, 48]\n\nprint(\"Window (hours) | Query Time (s)\")\nprint(\"---------------|---------------\")\n\nfor window in window_sizes:\n    start = time.time()\n\n    subprocess.run([\n        \"python\", \"anomaly_detector.py\",\n        \"--end\", \"NOW\",\n        \"--window\", str(window),\n        \"--temporal-method\", \"3sigma\"  # Fast method to isolate DB time\n    ], capture_output=True)\n\n    elapsed = time.time() - start\n    print(f\"{window:14d} | {elapsed:.3f}\")\n</code></pre>"},{"location":"api/examples/#integration-examples","title":"Integration Examples","text":""},{"location":"api/examples/#example-18-prometheus-exporter","title":"Example 18: Prometheus Exporter","text":"<p>Export metrics for Prometheus:</p> <pre><code>from prometheus_client import Gauge, start_http_server\nimport json\nimport subprocess\nimport time\n\n# Define metrics\ndevice_failures = Gauge('weather_device_failures', 'Number of device failures')\nweather_events = Gauge('weather_extreme_events', 'Number of weather events')\nanomalous_stations = Gauge('weather_anomalous_stations', 'Number of stations with anomalies')\n\ndef collect_metrics():\n    \"\"\"\n    Run detection and update Prometheus metrics.\n    \"\"\"\n    subprocess.run([\n        \"python\", \"anomaly_detector.py\",\n        \"--end\", \"NOW\",\n        \"--spatial-verify\",\n        \"--save\", \"/tmp/report.json\"\n    ], capture_output=True)\n\n    with open('/tmp/report.json', 'r') as f:\n        report = json.load(f)\n\n    device_failures.set(report['summary']['device_failures'])\n    weather_events.set(report['summary']['weather_events'])\n    anomalous_stations.set(report['summary']['anomalous_stations'])\n\nif __name__ == \"__main__\":\n    # Start Prometheus HTTP server\n    start_http_server(8000)\n\n    # Update metrics every 5 minutes\n    while True:\n        collect_metrics()\n        time.sleep(300)\n</code></pre> <p>These examples cover most common use cases. For more specific scenarios, refer to the API Reference or FAQ.</p>"},{"location":"api/overview/","title":"API Overview","text":"<p>The Real-Time Anomaly Detection system is primarily designed as a command-line tool but follows an API-first architecture that makes it easy to integrate into larger systems or wrap with a REST API.</p>"},{"location":"api/overview/#command-line-interface","title":"Command-Line Interface","text":""},{"location":"api/overview/#basic-usage","title":"Basic Usage","text":"<pre><code>python anomaly_detector.py [OPTIONS]\n</code></pre>"},{"location":"api/overview/#quick-examples","title":"Quick Examples","text":"<pre><code># Detect anomalies at current time\npython anomaly_detector.py --end \"NOW\" --temporal-method arima --spatial-verify\n\n# Analyze specific timestamp\npython anomaly_detector.py --end \"2025-11-22 17:00:00\" --window 6 --temporal-method arima --spatial-verify\n\n# Compare multiple methods\npython anomaly_detector.py --end \"NOW\" --temporal-method 3sigma --spatial-verify --save report_3sigma.json\npython anomaly_detector.py --end \"NOW\" --temporal-method arima --spatial-verify --save report_arima.json\n\n# Quick check without spatial verification\npython anomaly_detector.py --end \"NOW\" --temporal-method 3sigma\n</code></pre>"},{"location":"api/overview/#core-parameters","title":"Core Parameters","text":""},{"location":"api/overview/#required-parameters","title":"Required Parameters","text":"<p>None - all parameters have sensible defaults.</p>"},{"location":"api/overview/#optional-parameters","title":"Optional Parameters","text":""},{"location":"api/overview/#-end","title":"<code>--end</code>","text":"<p>Type: String (timestamp or \"NOW\") Default: \"NOW\" Description: The target timestamp to detect anomalies</p> <p>Formats:</p> <ul> <li><code>\"NOW\"</code>: Current time</li> <li><code>\"2025-11-22 17:00:00\"</code>: ISO format</li> <li><code>\"2025-11-22T17:00:00\"</code>: ISO format with T separator</li> <li><code>\"1732294800\"</code>: Unix timestamp</li> </ul> <p>Examples:</p> <pre><code># Current time\n--end \"NOW\"\n\n# Specific time (useful for historical analysis)\n--end \"2025-11-22 17:00:00\"\n\n# Unix timestamp\n--end \"1732294800\"\n</code></pre>"},{"location":"api/overview/#-window","title":"<code>--window</code>","text":"<p>Type: Integer Default: 6 Unit: Hours Description: Length of historical data to analyze</p> <p>Recommendations:</p> <ul> <li>Minimum: 1 hour (6 data points)</li> <li>Default: 6 hours (36 data points) - best for ARIMA</li> <li>Maximum: 24 hours (144 data points) - for STL with daily cycles</li> </ul> <p>Examples:</p> <pre><code># Quick check (1 hour)\n--window 1\n\n# Standard analysis (6 hours)\n--window 6\n\n# Full daily cycle (24 hours)\n--window 24\n</code></pre>"},{"location":"api/overview/#-temporal-method","title":"<code>--temporal-method</code>","text":"<p>Type: String (enum) Default: \"arima\" Options: <code>arima</code>, <code>3sigma</code>, <code>mad</code>, <code>iqr</code>, <code>isolation_forest</code>, <code>stl</code>, <code>lof</code> Description: Algorithm for temporal anomaly detection</p> <p>Comparison:</p> Method Speed Accuracy False Positives Use Case arima \u26a1\u26a1 \u2b50\u2b50\u2b50\u2b50\u2b50 Low Default (best overall) 3sigma \u26a1\u26a1\u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 Medium Quick checks mad \u26a1\u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50\u2b50 High Robust to outliers iqr \u26a1\u26a1\u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 Medium Exploratory isolation_forest \u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50\u2b50 Low Multidimensional stl \u26a1\u26a1 \u2b50\u2b50\u2b50\u2b50 Medium Seasonal data lof \u26a1\u26a1 \u2b50\u2b50\u2b50 Medium Density-based <p>Examples:</p> <pre><code># Best accuracy (default)\n--temporal-method arima\n\n# Fastest\n--temporal-method 3sigma\n\n# Most robust\n--temporal-method mad\n</code></pre> <p>See Detection Methods for detailed comparisons.</p>"},{"location":"api/overview/#-spatial-verify","title":"<code>--spatial-verify</code>","text":"<p>Type: Flag (boolean) Default: False Description: Enable spatial verification to distinguish weather events from device failures</p> <p>Recommendation: Always use this flag in production to reduce false positives by ~80%.</p> <p>Behavior:</p> <ul> <li>Without flag: All temporal anomalies are reported as-is</li> <li>With flag: Temporal anomalies are verified against neighbors</li> </ul> <p>Examples:</p> <pre><code># Without spatial verification (more false positives)\npython anomaly_detector.py --end \"NOW\"\n\n# With spatial verification (recommended)\npython anomaly_detector.py --end \"NOW\" --spatial-verify\n</code></pre>"},{"location":"api/overview/#-spatial-method","title":"<code>--spatial-method</code>","text":"<p>Type: String (enum) Default: \"pearson\" Options: <code>pearson</code>, <code>distance</code> Description: Method for spatial verification</p> <p>Options:</p> <ul> <li><code>pearson</code>: Trend correlation (default, recommended)</li> <li><code>distance</code>: Static value comparison (fallback)</li> </ul> <p>Examples:</p> <pre><code># Default (correlation-based)\n--spatial-method pearson\n\n# Fallback (value-based)\n--spatial-method distance\n</code></pre>"},{"location":"api/overview/#-neighbor-radius","title":"<code>--neighbor-radius</code>","text":"<p>Type: Float Default: 100.0 Unit: Kilometers Description: Maximum distance for neighbor selection</p> <p>Recommendations:</p> <ul> <li>Urban areas: 50-75 km</li> <li>Rural areas: 100-150 km</li> <li>Mountainous: 50 km (microclimates)</li> </ul> <p>Examples:</p> <pre><code># Default\n--neighbor-radius 100\n\n# Tighter neighborhood\n--neighbor-radius 50\n\n# Wider neighborhood\n--neighbor-radius 150\n</code></pre>"},{"location":"api/overview/#-save","title":"<code>--save</code>","text":"<p>Type: String (file path) Default: None Description: Save report to JSON file</p> <p>Examples:</p> <pre><code># Save with timestamp\n--save \"report_$(date +%Y%m%d_%H%M%S).json\"\n\n# Save with method name\n--save \"report_arima.json\"\n\n# Full path\n--save \"/var/log/anomaly_reports/report.json\"\n</code></pre>"},{"location":"api/overview/#-variables","title":"<code>--variables</code>","text":"<p>Type: String (comma-separated) Default: \"temp_out,out_hum,wind_speed,bar,rain\" Description: Variables to analyze</p> <p>Available Variables:</p> <ul> <li><code>temp_out</code>: Outdoor temperature</li> <li><code>out_hum</code>: Outdoor humidity</li> <li><code>wind_speed</code>: Wind speed</li> <li><code>bar</code>: Barometric pressure</li> <li><code>rain</code>: Rainfall</li> </ul> <p>Examples:</p> <pre><code># Only temperature\n--variables \"temp_out\"\n\n# Temperature and pressure\n--variables \"temp_out,bar\"\n\n# All variables (default)\n--variables \"temp_out,out_hum,wind_speed,bar,rain\"\n</code></pre>"},{"location":"api/overview/#-verbose","title":"<code>--verbose</code>","text":"<p>Type: Flag (boolean) Default: False Description: Enable detailed debug output</p> <p>Examples:</p> <pre><code># Standard output\npython anomaly_detector.py --end \"NOW\" --spatial-verify\n\n# Verbose output (for troubleshooting)\npython anomaly_detector.py --end \"NOW\" --spatial-verify --verbose\n</code></pre>"},{"location":"api/overview/#response-format","title":"Response Format","text":""},{"location":"api/overview/#console-output","title":"Console Output","text":"<p>Human-readable report with:</p> <ol> <li>Summary Section: Quick overview</li> <li>Detailed Reports: Per-station analysis</li> <li>Data Tables: For manual inspection (when anomalies found)</li> </ol> <p>Example:</p> <pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n ANOMALY DETECTION REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nEnd Time: 2025-11-22 17:00:00\nWindow: 6 hours\nMethod: arima\nSpatial Verification: Enabled\n\nTotal Stations: 14\nAnomalous Stations: 1\nNormal Stations: 13\n\nAnomaly Breakdown:\n  \ud83d\udd34 Device Failures: 0\n  \ud83c\udf27\ufe0f Weather Events: 1\n  \u26a0\ufe0f Suspected: 0\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n DETAILED REPORTS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[ STATION: uth_volos (Volos - University) ]\n  \u26a0\ufe0f  Temperature Anomaly:\n      Method: arima\n      Expected: 12.5\u00b0C | Actual: 10.1\u00b0C\n      \u2022 2025-11-22 17:00:00: 10.10\u00b0C -&gt; \ud83c\udf27\ufe0f Extreme Weather / Env Change\n        \u2514\u2500 Diag: Trend Consistent (Corr: 0.85, 3 neighbors)\n</code></pre>"},{"location":"api/overview/#json-output","title":"JSON Output","text":"<p>Structured format for programmatic processing:</p> <pre><code>{\n  \"metadata\": {\n    \"timestamp\": \"2025-11-22T17:00:00Z\",\n    \"window_hours\": 6,\n    \"temporal_method\": \"arima\",\n    \"spatial_verify\": true,\n    \"spatial_method\": \"pearson\"\n  },\n  \"summary\": {\n    \"total_stations\": 14,\n    \"anomalous_stations\": 1,\n    \"normal_stations\": 13,\n    \"device_failures\": 0,\n    \"weather_events\": 1,\n    \"suspected\": 0\n  },\n  \"anomalies\": [\n    {\n      \"station_id\": \"uth_volos\",\n      \"station_name\": \"Volos - University\",\n      \"variable\": \"temp_out\",\n      \"timestamp\": \"2025-11-22T17:00:00Z\",\n      \"actual_value\": 10.1,\n      \"expected_value\": 12.5,\n      \"deviation\": -2.4,\n      \"temporal_method\": \"arima\",\n      \"classification\": \"weather_event\",\n      \"spatial_verification\": {\n        \"enabled\": true,\n        \"method\": \"pearson\",\n        \"correlation\": 0.85,\n        \"neighbors_checked\": 3,\n        \"neighbors\": [\"volos\", \"zagora\", \"larissa\"]\n      }\n    }\n  ],\n  \"normal_stations\": [\n    \"volos\",\n    \"zagora\",\n    \"pelion\",\n    \"anavra\",\n    \"domokos\",\n    \"karditsa\",\n    \"larissa\",\n    \"trikala\",\n    \"pyli\",\n    \"metsovo\",\n    \"ioannina\",\n    \"agrinio\",\n    \"preveza\"\n  ]\n}\n</code></pre>"},{"location":"api/overview/#exit-codes","title":"Exit Codes","text":"Code Meaning Description 0 Success Detection completed successfully 1 Error General error (check error message) 2 Database Error Cannot connect to database 3 Invalid Parameters Invalid command-line arguments 4 Insufficient Data Not enough historical data for analysis"},{"location":"api/overview/#python-api","title":"Python API","text":"<p>While primarily a CLI tool, the detector can be imported as a Python module:</p> <pre><code>from anomaly_detector import AnomalyDetector, TemporalConfig, SpatialConfig\n\n# Initialize detector\ndetector = AnomalyDetector(database_path=\"weather_stream.db\")\n\n# Configure detection\ntemporal_config = TemporalConfig(\n    method=\"arima\",\n    window_hours=6\n)\n\nspatial_config = SpatialConfig(\n    enabled=True,\n    method=\"pearson\",\n    neighbor_radius_km=100\n)\n\n# Run detection\nresults = detector.detect(\n    end_time=\"2025-11-22 17:00:00\",\n    temporal_config=temporal_config,\n    spatial_config=spatial_config,\n    variables=[\"temp_out\", \"out_hum\"]\n)\n\n# Process results\nfor anomaly in results.anomalies:\n    print(f\"Station {anomaly.station_id}: {anomaly.classification}\")\n    if anomaly.classification == \"device_failure\":\n        send_alert(anomaly)\n</code></pre>"},{"location":"api/overview/#rest-api-wrapper-future","title":"REST API Wrapper (Future)","text":"<p>The system is designed to be easily wrapped in a REST API. Here's a proposed interface:</p> <pre><code>POST /api/v1/detect\nContent-Type: application/json\n\n{\n  \"end_time\": \"2025-11-22T17:00:00Z\",\n  \"window_hours\": 6,\n  \"temporal_method\": \"arima\",\n  \"spatial_verify\": true,\n  \"variables\": [\"temp_out\", \"out_hum\"]\n}\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 200 OK\nContent-Type: application/json\n\n{\n  \"summary\": {\n    \"device_failures\": 0,\n    \"weather_events\": 1,\n    \"suspected\": 0\n  },\n  \"anomalies\": [...]\n}\n</code></pre> <p>See the GitHub Issues for REST API development progress.</p>"},{"location":"api/parameters/","title":"Parameters Reference","text":"<p>Complete reference for all command-line parameters and configuration options.</p>"},{"location":"api/parameters/#command-line-parameters","title":"Command-Line Parameters","text":""},{"location":"api/parameters/#detection-window","title":"Detection Window","text":""},{"location":"api/parameters/#-end","title":"<code>--end</code>","text":"<p>Specifies the target timestamp for anomaly detection.</p> Property Value Type String Default \"NOW\" Required No Example <code>--end \"2025-11-22 17:00:00\"</code> <p>Accepted Formats:</p> <pre><code># Current time\n--end \"NOW\"\n\n# ISO 8601 format\n--end \"2025-11-22T17:00:00\"\n--end \"2025-11-22 17:00:00\"\n\n# Unix timestamp\n--end \"1732294800\"\n</code></pre> <p>Use Cases:</p> <ul> <li>Real-time monitoring: <code>--end \"NOW\"</code></li> <li>Historical analysis: <code>--end \"2025-11-01 12:00:00\"</code></li> <li>Batch processing: Loop through timestamps</li> </ul>"},{"location":"api/parameters/#-window","title":"<code>--window</code>","text":"<p>Length of historical data to analyze (in hours).</p> Property Value Type Integer Default 6 Unit Hours Range 1-48 Example <code>--window 6</code> <p>Guidelines:</p> Window Size Data Points (10min) Use Case 1 hour 6 Quick checks, testing 6 hours 36 Recommended for ARIMA 12 hours 72 Capturing half-day cycles 24 hours 144 Full daily cycle (for STL) 48 hours 288 Multi-day analysis <p>Performance Impact</p> <p>Larger windows increase computation time, especially for ARIMA and STL methods.</p>"},{"location":"api/parameters/#temporal-detection","title":"Temporal Detection","text":""},{"location":"api/parameters/#-temporal-method","title":"<code>--temporal-method</code>","text":"<p>Algorithm for temporal anomaly detection.</p> Property Value Type String (enum) Default \"arima\" Options <code>arima</code>, <code>3sigma</code>, <code>mad</code>, <code>iqr</code>, <code>isolation_forest</code>, <code>stl</code>, <code>lof</code> Example <code>--temporal-method arima</code> <p>Method Selection Guide:</p> For AccuracyFor SpeedFor Robustness <ol> <li>arima - Best overall</li> <li>stl - If strong daily seasonality</li> <li>isolation_forest - For multivariate patterns</li> </ol> <ol> <li>3sigma - Fastest</li> <li>iqr - Very fast</li> <li>mad - Fast and robust</li> </ol> <ol> <li>mad - Most robust to outliers</li> <li>iqr - Robust, simple</li> <li>arima - Adapts to trends</li> </ol> <p>Detailed Comparison: See Detection Methods</p>"},{"location":"api/parameters/#-temporal-threshold","title":"<code>--temporal-threshold</code>","text":"<p>Threshold for temporal anomaly detection (method-specific).</p> Property Value Type Float Default Method-dependent Example <code>--temporal-threshold 3.0</code> <p>Default Thresholds by Method:</p> Method Default Interpretation Adjustable Range arima 0.95 Confidence level 0.90 - 0.99 3sigma 3.0 Standard deviations 2.0 - 4.0 mad 3.5 MAD units 2.5 - 5.0 iqr 1.5 IQR multiplier 1.0 - 3.0 isolation_forest 0.1 Contamination rate 0.05 - 0.2 stl 3.0 Residual sigma 2.0 - 4.0 lof 0.1 Contamination rate 0.05 - 0.2 <p>Tuning:</p> <ul> <li>Lower threshold \u2192 More sensitive \u2192 More detections (higher recall)</li> <li>Higher threshold \u2192 Less sensitive \u2192 Fewer detections (higher precision)</li> </ul>"},{"location":"api/parameters/#spatial-verification","title":"Spatial Verification","text":""},{"location":"api/parameters/#-spatial-verify","title":"<code>--spatial-verify</code>","text":"<p>Enable spatial verification to distinguish weather events from device failures.</p> Property Value Type Boolean flag Default False Example <code>--spatial-verify</code> <p>Impact:</p> Metric Without With False Positives ~40% ~5% True Positives 100% 100% Processing Time 100% 120% <p>Production Recommendation</p> <p>Always enable spatial verification in production environments to reduce false alarms.</p>"},{"location":"api/parameters/#-spatial-method","title":"<code>--spatial-method</code>","text":"<p>Method for spatial verification.</p> Property Value Type String (enum) Default \"pearson\" Options <code>pearson</code>, <code>distance</code> Example <code>--spatial-method pearson</code> <p>Method Comparison:</p> Method Measures Advantages Disadvantages pearson Trend correlation Robust to different baselines Requires sufficient data distance Value deviation Simple, fast Sensitive to baseline differences"},{"location":"api/parameters/#-neighbor-radius","title":"<code>--neighbor-radius</code>","text":"<p>Maximum distance (in kilometers) for neighbor selection.</p> Property Value Type Float Default 100.0 Unit Kilometers Range 10 - 500 Example <code>--neighbor-radius 100</code> <p>Tuning Guidelines:</p> Scenario Recommended Radius Rationale Dense urban 50 km High station density Rural plains 100 km Default Mountainous 50 km Microclimates Sparse network 150-200 km Find enough neighbors Continental scale 200-500 km Large-scale phenomena"},{"location":"api/parameters/#-correlation-threshold-high","title":"<code>--correlation-threshold-high</code>","text":"<p>Minimum correlation to classify as \"weather event\".</p> Property Value Type Float Default 0.6 Range 0.5 - 0.9 Example <code>--correlation-threshold-high 0.6</code> <p>Impact:</p> <ul> <li>Lower (e.g., 0.5): More anomalies classified as weather events</li> <li>Higher (e.g., 0.8): Stricter criteria, fewer weather events</li> </ul>"},{"location":"api/parameters/#-correlation-threshold-low","title":"<code>--correlation-threshold-low</code>","text":"<p>Maximum correlation to classify as \"device failure\".</p> Property Value Type Float Default 0.3 Range 0.1 - 0.4 Example <code>--correlation-threshold-low 0.3</code> <p>Impact:</p> <ul> <li>Lower (e.g., 0.2): Stricter criteria for device failures</li> <li>Higher (e.g., 0.4): More anomalies classified as device failures</li> </ul>"},{"location":"api/parameters/#variables","title":"Variables","text":""},{"location":"api/parameters/#-variables","title":"<code>--variables</code>","text":"<p>Comma-separated list of variables to analyze.</p> Property Value Type String (comma-separated) Default \"temp_out,out_hum,wind_speed,bar,rain\" Example <code>--variables \"temp_out,bar\"</code> <p>Available Variables:</p> Variable Description Unit Typical Range temp_out Outdoor temperature \u00b0C -10 to 40 out_hum Outdoor humidity % 0 to 100 wind_speed Wind speed km/h 0 to 100 bar Barometric pressure hPa 950 to 1050 rain Rainfall rate mm 0 to 50 <p>Use Cases:</p> <pre><code># Only temperature (fastest)\n--variables \"temp_out\"\n\n# Temperature and pressure (common failure indicators)\n--variables \"temp_out,bar\"\n\n# All variables except wind (wind is noisy)\n--variables \"temp_out,out_hum,bar,rain\"\n</code></pre>"},{"location":"api/parameters/#output","title":"Output","text":""},{"location":"api/parameters/#-save","title":"<code>--save</code>","text":"<p>Save detection report to JSON file.</p> Property Value Type String (file path) Default None (console only) Example <code>--save report.json</code> <p>Examples:</p> <pre><code># Simple filename\n--save report.json\n\n# With timestamp\n--save \"report_$(date +%Y%m%d_%H%M%S).json\"\n\n# Full path\n--save \"/var/log/anomaly_reports/report.json\"\n\n# Method-specific\n--save \"report_${METHOD}_$(date +%Y%m%d).json\"\n</code></pre>"},{"location":"api/parameters/#-output-format","title":"<code>--output-format</code>","text":"<p>Output format for saved reports.</p> Property Value Type String (enum) Default \"json\" Options <code>json</code>, <code>csv</code>, <code>html</code> Example <code>--output-format json</code> <p>Format Comparison:</p> Format Use Case Parseable Human-Readable json API integration, storage \u2705 \u26a0\ufe0f csv Spreadsheet analysis \u2705 \u2705 html Email reports, dashboards \u274c \u2705\u2705"},{"location":"api/parameters/#-verbose","title":"<code>--verbose</code>","text":"<p>Enable detailed debug output.</p> Property Value Type Boolean flag Default False Example <code>--verbose</code> <p>Output Difference:</p> StandardVerbose <pre><code>Total Stations: 14\nAnomalous Stations: 1\nDevice Failures: 0\n</code></pre> <pre><code>[DEBUG] Connecting to database: weather_stream.db\n[DEBUG] Loading station metadata...\n[DEBUG] Found 14 stations\n[DEBUG] Querying data window: 2025-11-22 11:00:00 to 17:00:00\n[DEBUG] Retrieved 504 observations (14 stations \u00d7 36 timestamps)\n[DEBUG] Starting temporal detection (method: arima)\n[DEBUG] Station uth_volos: Analyzing temp_out...\n[DEBUG] ARIMA model fit: AIC=125.4, BIC=130.2\n[DEBUG] Forecast: 12.5\u00b0C \u00b1 1.8\u00b0C (95% CI)\n[DEBUG] Actual: 10.1\u00b0C\n[DEBUG] Anomaly detected: Outside confidence interval\n[DEBUG] Starting spatial verification...\n[DEBUG] Found 3 neighbors within 100km\n[DEBUG] Pearson correlation: 0.85 (high)\n[DEBUG] Classification: Weather Event\nTotal Stations: 14\nAnomalous Stations: 1\nDevice Failures: 0\n</code></pre>"},{"location":"api/parameters/#database","title":"Database","text":""},{"location":"api/parameters/#-database","title":"<code>--database</code>","text":"<p>Path to SQLite database or PostgreSQL connection string.</p> Property Value Type String (path or URL) Default \"weather_stream.db\" Example <code>--database /path/to/db.sqlite</code> <p>Examples:</p> <pre><code># SQLite (relative path)\n--database weather_stream.db\n\n# SQLite (absolute path)\n--database /var/lib/weather/stream.db\n\n# PostgreSQL / TimescaleDB\n--database \"postgresql://user:pass@localhost:5432/weather\"\n</code></pre>"},{"location":"api/parameters/#configuration-file-future","title":"Configuration File (Future)","text":"<p>For convenience, parameters can be saved in a configuration file:</p> <pre><code># anomaly_detection_config.yaml\n\ndetection:\n  window_hours: 6\n  temporal_method: arima\n  temporal_threshold: 0.95\n\nspatial:\n  enabled: true\n  method: pearson\n  neighbor_radius: 100\n  correlation_threshold_high: 0.6\n  correlation_threshold_low: 0.3\n\nvariables:\n  - temp_out\n  - out_hum\n  - wind_speed\n  - bar\n  - rain\n\noutput:\n  save_path: /var/log/anomaly_reports\n  format: json\n  verbose: false\n\ndatabase:\n  path: weather_stream.db\n</code></pre> <p>Usage:</p> <pre><code>python anomaly_detector.py --config anomaly_detection_config.yaml\n</code></pre> <p>Roadmap Feature</p> <p>Configuration file support is planned for a future release.</p>"},{"location":"api/parameters/#environment-variables","title":"Environment Variables","text":"<p>Some parameters can be set via environment variables:</p> Variable Equivalent Parameter Example <code>WEATHER_DB</code> <code>--database</code> <code>export WEATHER_DB=/path/to/db</code> <code>DETECTION_METHOD</code> <code>--temporal-method</code> <code>export DETECTION_METHOD=arima</code> <code>SPATIAL_VERIFY</code> <code>--spatial-verify</code> <code>export SPATIAL_VERIFY=1</code> <p>Priority order (highest to lowest):</p> <ol> <li>Command-line arguments</li> <li>Configuration file (future)</li> <li>Environment variables</li> <li>Default values</li> </ol>"},{"location":"api/parameters/#validation","title":"Validation","text":"<p>The system validates all parameters before execution:</p>"},{"location":"api/parameters/#invalid-parameter-example","title":"Invalid Parameter Example","text":"<pre><code>$ python anomaly_detector.py --window 0\nError: --window must be &gt;= 1\n\n$ python anomaly_detector.py --temporal-method invalid\nError: --temporal-method must be one of: arima, 3sigma, mad, iqr, isolation_forest, stl, lof\n\n$ python anomaly_detector.py --neighbor-radius -10\nError: --neighbor-radius must be positive\n</code></pre>"},{"location":"api/parameters/#warnings","title":"Warnings","text":"<p>Some combinations trigger warnings but don't fail:</p> <pre><code>$ python anomaly_detector.py --window 1 --temporal-method arima\nWarning: ARIMA works best with window &gt;= 6 hours. Results may be inaccurate.\n\n$ python anomaly_detector.py --temporal-method 3sigma --window 24\nWarning: Window size of 24 hours is excessive for 3-sigma. Consider reducing to 6 hours.\n</code></pre>"},{"location":"api/response/","title":"Response Format","text":""},{"location":"api/response/#console-output","title":"Console Output","text":""},{"location":"api/response/#structure","title":"Structure","text":"<p>Console output follows this structure:</p> <ol> <li>Header: Report metadata</li> <li>Summary: High-level statistics</li> <li>Detailed Reports: Per-station anomaly details</li> <li>Data Tables: Supporting evidence (when anomalies found)</li> </ol>"},{"location":"api/response/#example-output","title":"Example Output","text":"<pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n ANOMALY DETECTION REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nEnd Time: 2025-11-22 17:00:00\nWindow: 6 hours\nMethod: arima\nSpatial Verification: Enabled\n\nTotal Stations: 14\nAnomalous Stations: 2\nNormal Stations: 12\n\nAnomaly Breakdown:\n  \ud83d\udd34 Device Failures: 1      &lt;-- CHECK THIS (Real Hardware Issues)\n  \ud83c\udf27\ufe0f Weather Events: 1       &lt;-- IGNORE THIS (Just Weather)\n  \u26a0\ufe0f Suspected: 0            &lt;-- MANUAL CHECK (Uncertain Cases)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n DETAILED REPORTS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[ STATION: uth_volos (Volos - University) ]\n  \u26a0\ufe0f  Temperature Anomaly:\n      Method: arima\n      Expected: 12.5\u00b0C | Actual: 10.1\u00b0C\n      \u2022 2025-11-22 17:00:00: 10.10\u00b0C -&gt; \ud83c\udf27\ufe0f Extreme Weather / Env Change\n        \u2514\u2500 Diag: Trend Consistent (Corr: 0.85, 3 neighbors)\n\n[ STATION: pelion (Pelion Mountain) ]\n  \ud83d\udd34 Temperature Anomaly:\n      Method: arima\n      Expected: 5.2\u00b0C | Actual: 99.0\u00b0C\n      \u2022 2025-11-22 17:00:00: 99.00\u00b0C -&gt; \ud83d\udd34 Device Failure\n        \u2514\u2500 Diag: Trend Inconsistent (Corr: 0.05, 2 neighbors)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n NEIGHBOR COMPARISON\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nStation: pelion (Anomalous)\nNeighbors: zagora (28.5km), volos (32.1km)\n\nTime                 | pelion (\u00b0C) | zagora (\u00b0C) | volos (\u00b0C)\n---------------------|-------------|-------------|-------------\n2025-11-22 11:00:00  | 5.2         | 8.1         | 10.2\n2025-11-22 11:10:00  | 5.3         | 8.0         | 10.3\n...\n2025-11-22 16:50:00  | 5.1         | 7.9         | 10.1\n2025-11-22 17:00:00  | 99.0 \u26a0\ufe0f     | 7.8         | 10.0\n\nObservation: pelion suddenly jumps to 99\u00b0C while neighbors remain stable\n\u2192 Classification: Device Failure\n</code></pre>"},{"location":"api/response/#summary-section","title":"Summary Section","text":""},{"location":"api/response/#field-descriptions","title":"Field Descriptions","text":"Field Description Values End Time Target timestamp for detection ISO 8601 format Window Historical window size Hours Method Temporal detection algorithm arima, 3sigma, etc. Spatial Verification Whether spatial verify is enabled Enabled/Disabled Total Stations Number of monitored stations Integer Anomalous Stations Stations with detected anomalies Integer Normal Stations Stations with no anomalies Integer Device Failures Confirmed hardware issues Action required Weather Events Extreme weather patterns No action Suspected Uncertain cases Manual review"},{"location":"api/response/#interpretation-guide","title":"Interpretation Guide","text":"<pre><code>Device Failures: N    \u2192 Check N station(s) for hardware issues\nWeather Events: M     \u2192 Ignore (M station(s) experiencing weather)\nSuspected: K          \u2192 Review K station(s) manually\n</code></pre>"},{"location":"api/response/#detailed-reports-section","title":"Detailed Reports Section","text":""},{"location":"api/response/#anomaly-entry-format","title":"Anomaly Entry Format","text":"<pre><code>[ STATION: {station_id} ({station_name}) ]\n  {icon} {variable} Anomaly:\n      Method: {detection_method}\n      Expected: {predicted_value} | Actual: {actual_value}\n      \u2022 {timestamp}: {value} -&gt; {classification_icon} {classification_text}\n        \u2514\u2500 Diag: {spatial_diagnosis}\n</code></pre>"},{"location":"api/response/#icons","title":"Icons","text":"Icon Meaning \ud83d\udd34 Device Failure \ud83c\udf27\ufe0f Weather Event \u26a0\ufe0f Suspected / Under Review \u2705 Normal (verbose mode)"},{"location":"api/response/#spatial-diagnosis","title":"Spatial Diagnosis","text":"Text Interpretation Correlation Range Trend Consistent Neighbors show same pattern &gt; 0.6 Trend Inconsistent Only this station anomalous &lt; 0.3 Trend Unclear Uncertain correlation 0.3 - 0.6 Trend Skipped: no_neighbors No neighbors within radius N/A"},{"location":"api/response/#data-tables","title":"Data Tables","text":"<p>When anomalies are detected with spatial verification, the system prints comparison tables:</p> <pre><code>Time                 | suspect | neighbor1 | neighbor2 | neighbor3\n---------------------|---------|-----------|-----------|----------\n2025-11-22 16:00:00  | 12.5    | 12.8      | 12.3      | 12.6\n2025-11-22 16:10:00  | 12.3    | 12.5      | 12.1      | 12.4\n2025-11-22 16:20:00  | 12.0    | 12.2      | 11.9      | 12.1\n2025-11-22 16:30:00  | 11.8    | 11.9      | 11.6      | 11.8\n2025-11-22 16:40:00  | 11.5    | 11.7      | 11.4      | 11.6\n2025-11-22 16:50:00  | 11.2    | 11.4      | 11.1      | 11.3\n2025-11-22 17:00:00  | 10.1 \u26a0\ufe0f  | 11.2      | 10.9      | 11.1\n</code></pre> <p>Purpose: Allows manual inspection to verify the classification.</p>"},{"location":"api/response/#json-output","title":"JSON Output","text":""},{"location":"api/response/#schema","title":"Schema","text":"<pre><code>{\n  \"metadata\": {\n    \"timestamp\": \"string (ISO 8601)\",\n    \"window_hours\": \"integer\",\n    \"temporal_method\": \"string\",\n    \"temporal_threshold\": \"float\",\n    \"spatial_verify\": \"boolean\",\n    \"spatial_method\": \"string\",\n    \"neighbor_radius\": \"float\",\n    \"variables\": [\"string\"],\n    \"database\": \"string\"\n  },\n  \"summary\": {\n    \"total_stations\": \"integer\",\n    \"anomalous_stations\": \"integer\",\n    \"normal_stations\": \"integer\",\n    \"device_failures\": \"integer\",\n    \"weather_events\": \"integer\",\n    \"suspected\": \"integer\"\n  },\n  \"anomalies\": [\n    {\n      \"station_id\": \"string\",\n      \"station_name\": \"string\",\n      \"variable\": \"string\",\n      \"timestamp\": \"string (ISO 8601)\",\n      \"actual_value\": \"float\",\n      \"expected_value\": \"float\",\n      \"deviation\": \"float\",\n      \"temporal_method\": \"string\",\n      \"classification\": \"string\",\n      \"spatial_verification\": {\n        \"enabled\": \"boolean\",\n        \"method\": \"string\",\n        \"correlation\": \"float\",\n        \"neighbors_checked\": \"integer\",\n        \"neighbors\": [\"string\"]\n      }\n    }\n  ],\n  \"normal_stations\": [\"string\"]\n}\n</code></pre>"},{"location":"api/response/#full-example","title":"Full Example","text":"<pre><code>{\n  \"metadata\": {\n    \"timestamp\": \"2025-11-22T17:00:00Z\",\n    \"window_hours\": 6,\n    \"temporal_method\": \"arima\",\n    \"temporal_threshold\": 0.95,\n    \"spatial_verify\": true,\n    \"spatial_method\": \"pearson\",\n    \"neighbor_radius\": 100.0,\n    \"variables\": [\"temp_out\", \"out_hum\", \"wind_speed\", \"bar\", \"rain\"],\n    \"database\": \"weather_stream.db\"\n  },\n  \"summary\": {\n    \"total_stations\": 14,\n    \"anomalous_stations\": 2,\n    \"normal_stations\": 12,\n    \"device_failures\": 1,\n    \"weather_events\": 1,\n    \"suspected\": 0\n  },\n  \"anomalies\": [\n    {\n      \"station_id\": \"uth_volos\",\n      \"station_name\": \"Volos - University\",\n      \"variable\": \"temp_out\",\n      \"timestamp\": \"2025-11-22T17:00:00Z\",\n      \"actual_value\": 10.1,\n      \"expected_value\": 12.5,\n      \"deviation\": -2.4,\n      \"temporal_method\": \"arima\",\n      \"classification\": \"weather_event\",\n      \"spatial_verification\": {\n        \"enabled\": true,\n        \"method\": \"pearson\",\n        \"correlation\": 0.85,\n        \"neighbors_checked\": 3,\n        \"neighbors\": [\"volos\", \"zagora\", \"larissa\"]\n      }\n    },\n    {\n      \"station_id\": \"pelion\",\n      \"station_name\": \"Pelion Mountain\",\n      \"variable\": \"temp_out\",\n      \"timestamp\": \"2025-11-22T17:00:00Z\",\n      \"actual_value\": 99.0,\n      \"expected_value\": 5.2,\n      \"deviation\": 93.8,\n      \"temporal_method\": \"arima\",\n      \"classification\": \"device_failure\",\n      \"spatial_verification\": {\n        \"enabled\": true,\n        \"method\": \"pearson\",\n        \"correlation\": 0.05,\n        \"neighbors_checked\": 2,\n        \"neighbors\": [\"zagora\", \"volos\"]\n      }\n    }\n  ],\n  \"normal_stations\": [\n    \"volos\",\n    \"zagora\",\n    \"anavra\",\n    \"domokos\",\n    \"karditsa\",\n    \"larissa\",\n    \"trikala\",\n    \"pyli\",\n    \"metsovo\",\n    \"ioannina\",\n    \"agrinio\",\n    \"preveza\"\n  ]\n}\n</code></pre>"},{"location":"api/response/#field-descriptions_1","title":"Field Descriptions","text":""},{"location":"api/response/#metadata-object","title":"Metadata Object","text":"Field Type Description timestamp string Detection timestamp (ISO 8601) window_hours integer Historical window size temporal_method string Detection algorithm used temporal_threshold float Threshold for temporal detection spatial_verify boolean Whether spatial verification was enabled spatial_method string Spatial verification method (if enabled) neighbor_radius float Neighbor selection radius (km) variables array Variables analyzed database string Database path/URL"},{"location":"api/response/#summary-object","title":"Summary Object","text":"Field Type Description total_stations integer Total monitored stations anomalous_stations integer Stations with anomalies normal_stations integer Stations without anomalies device_failures integer Confirmed device failures weather_events integer Confirmed weather events suspected integer Uncertain cases"},{"location":"api/response/#anomaly-object","title":"Anomaly Object","text":"Field Type Description station_id string Unique station identifier station_name string Human-readable station name variable string Affected variable (temp_out, etc.) timestamp string Anomaly timestamp (ISO 8601) actual_value float Measured value expected_value float Predicted/expected value deviation float Difference (actual - expected) temporal_method string Detection method used classification string Final classification spatial_verification object Spatial verification details"},{"location":"api/response/#spatial-verification-object","title":"Spatial Verification Object","text":"Field Type Description enabled boolean Whether spatial verify was used method string Verification method (pearson/distance) correlation float Average correlation with neighbors neighbors_checked integer Number of neighbors compared neighbors array List of neighbor station IDs"},{"location":"api/response/#classification-values","title":"Classification Values","text":"Value Meaning Action Required \"device_failure\" Hardware malfunction \u2705 Yes - Check equipment \"weather_event\" Extreme weather \u274c No - Normal \"suspected\" Uncertain \u26a0\ufe0f Maybe - Manual review"},{"location":"api/response/#csv-output-future","title":"CSV Output (Future)","text":"<p>Flattened format for spreadsheet analysis:</p> <pre><code>timestamp,station_id,station_name,variable,actual,expected,deviation,method,classification,correlation,neighbors\n2025-11-22T17:00:00Z,uth_volos,Volos - University,temp_out,10.1,12.5,-2.4,arima,weather_event,0.85,3\n2025-11-22T17:00:00Z,pelion,Pelion Mountain,temp_out,99.0,5.2,93.8,arima,device_failure,0.05,2\n</code></pre>"},{"location":"api/response/#html-output-future","title":"HTML Output (Future)","text":"<p>Rich formatted report with charts and tables:</p> <ul> <li>Summary dashboard</li> <li>Station-by-station cards</li> <li>Time series plots</li> <li>Correlation heatmaps</li> <li>Interactive maps</li> </ul>"},{"location":"api/response/#exit-codes","title":"Exit Codes","text":"<p>Programs can check the exit code for automation:</p> <pre><code>python anomaly_detector.py --end \"NOW\" --spatial-verify\nEXITCODE=$?\n\nif [ $EXITCODE -eq 0 ]; then\n    echo \"Detection completed successfully\"\nelif [ $EXITCODE -eq 1 ]; then\n    echo \"Error occurred\"\n    exit 1\nelif [ $EXITCODE -eq 2 ]; then\n    echo \"Database error\"\n    exit 2\nfi\n</code></pre> Exit Code Meaning stdout stderr 0 Success Report Empty 1 General error Partial report Error message 2 Database error Empty Error message 3 Invalid parameters Empty Usage help 4 Insufficient data Empty Error message"},{"location":"api/response/#programmatic-parsing","title":"Programmatic Parsing","text":""},{"location":"api/response/#parsing-json-with-python","title":"Parsing JSON with Python","text":"<pre><code>import json\n\nwith open('report.json', 'r') as f:\n    report = json.load(f)\n\n# Check for device failures\nif report['summary']['device_failures'] &gt; 0:\n    for anomaly in report['anomalies']:\n        if anomaly['classification'] == 'device_failure':\n            print(f\"ALERT: {anomaly['station_id']} - {anomaly['variable']}\")\n            send_alert(anomaly)\n</code></pre>"},{"location":"api/response/#parsing-json-with-jq","title":"Parsing JSON with jq","text":"<pre><code># Extract device failures only\ncat report.json | jq '.anomalies[] | select(.classification == \"device_failure\")'\n\n# Count anomalies by type\ncat report.json | jq '.summary'\n\n# Get affected station IDs\ncat report.json | jq -r '.anomalies[].station_id'\n</code></pre>"},{"location":"api/response/#parsing-console-output","title":"Parsing Console Output","text":"<p>For scripts that cannot use JSON:</p> <pre><code># Extract device failure count\npython anomaly_detector.py | grep \"Device Failures\" | awk '{print $3}'\n\n# Check if any device failures exist\nif python anomaly_detector.py | grep -q \"Device Failures: [1-9]\"; then\n    echo \"Device failures detected!\"\nfi\n</code></pre>"},{"location":"examples/device-failure/","title":"Device Failure Example","text":""},{"location":"examples/device-failure/#scenario-temperature-sensor-malfunction","title":"Scenario: Temperature Sensor Malfunction","text":""},{"location":"examples/device-failure/#context","title":"Context","text":"<p>On November 18, 2025, the temperature sensor at Pelion station began reporting unrealistic values (99\u00b0C), while neighboring stations showed normal readings.</p>"},{"location":"examples/device-failure/#detection-run","title":"Detection Run","text":"<pre><code>python anomaly_detector.py \\\n  --end \"2025-11-18 16:00:00\" \\\n  --window 6 \\\n  --temporal-method arima \\\n  --spatial-verify\n</code></pre>"},{"location":"examples/device-failure/#console-output","title":"Console Output","text":"<pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n ANOMALY DETECTION REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nEnd Time: 2025-11-18 16:00:00\nWindow: 6 hours\nMethod: arima\nSpatial Verification: Enabled\n\nTotal Stations: 14\nAnomalous Stations: 1\nNormal Stations: 13\n\nAnomaly Breakdown:\n  \ud83d\udd34 Device Failures: 1      &lt;-- \u26a0\ufe0f ACTION REQUIRED!\n  \ud83c\udf27\ufe0f Weather Events: 0\n  \u26a0\ufe0f Suspected: 0\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n DETAILED REPORTS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[ STATION: pelion (Pelion Mountain) ]\n  \ud83d\udd34 Temperature Anomaly:\n      Method: arima\n      Expected: 5.2\u00b0C | Actual: 99.0\u00b0C\n      \u2022 2025-11-18 16:00:00: 99.00\u00b0C -&gt; \ud83d\udd34 Device Failure\n        \u2514\u2500 Diag: Trend Inconsistent (Corr: 0.05, 2 neighbors)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n NEIGHBOR COMPARISON - Station: pelion\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTime                 | pelion  | zagora | volos\n---------------------|---------|--------|-------\n2025-11-18 10:00:00  | 5.2     | 8.1    | 10.2\n2025-11-18 10:30:00  | 5.3     | 8.2    | 10.3\n2025-11-18 11:00:00  | 5.4     | 8.3    | 10.4\n2025-11-18 11:30:00  | 5.3     | 8.2    | 10.5\n2025-11-18 12:00:00  | 5.2     | 8.1    | 10.6\n2025-11-18 12:30:00  | 5.1     | 8.0    | 10.7\n2025-11-18 13:00:00  | 5.0     | 7.9    | 10.8\n2025-11-18 13:30:00  | 4.9     | 7.8    | 10.9\n2025-11-18 14:00:00  | 4.8     | 7.7    | 11.0\n2025-11-18 14:30:00  | 4.9     | 7.6    | 11.1\n2025-11-18 15:00:00  | 5.0     | 7.7    | 11.2\n2025-11-18 15:30:00  | 5.1     | 7.8    | 11.3\n2025-11-18 16:00:00  | 99.0 \ud83d\udd34 | 7.9    | 11.4\n\nObservation: pelion suddenly jumps to 99\u00b0C while neighbors remain stable\n\u2192 Classification: Device Failure (Sensor Error)\n\nRECOMMENDATION: Inspect Pelion station temperature sensor\n</code></pre>"},{"location":"examples/device-failure/#analysis","title":"Analysis","text":""},{"location":"examples/device-failure/#why-was-this-classified-as-device-failure","title":"Why Was This Classified as Device Failure?","text":"<ol> <li>Isolated Anomaly: Only 1 station affected (out of 14)</li> <li>Low Spatial Correlation: 0.05 (&lt;&lt; 0.3 threshold)</li> <li>Unrealistic Value: 99\u00b0C is physically impossible for this location (mountain, altitude 1200m)</li> <li>Neighbors Normal: Nearby stations show stable, expected temperatures</li> </ol>"},{"location":"examples/device-failure/#spatial-correlation-details","title":"Spatial Correlation Details","text":"<pre><code>Station Pair       | Correlation | Distance | Neighbor Trend\n-------------------|-------------|----------|----------------\npelion \u2194 zagora    | 0.03        | 32.1 km  | Stable ~8\u00b0C\npelion \u2194 volos     | 0.08        | 35.4 km  | Stable ~11\u00b0C\n</code></pre> <p>Interpretation: Pelion's behavior is completely uncorrelated with neighbors \u2192 Isolated issue</p>"},{"location":"examples/device-failure/#time-series-visualization","title":"Time Series Visualization","text":""},{"location":"examples/device-failure/#temperature-comparison","title":"Temperature Comparison","text":"<pre><code>Temp (\u00b0C)\n   100 \u2524                          \u25cf \u2190 pelion (ANOMALY)\n    90 \u2524\n    80 \u2524\n    70 \u2524\n    60 \u2524\n    50 \u2524\n    40 \u2524\n    30 \u2524\n    20 \u2524\n    11 \u2524                      \u2500\u2500\u2500\u2500\u2500\u25cf volos (NORMAL)\n     8 \u2524                  \u2500\u2500\u2500\u2500\u2500\u25cf     zagora (NORMAL)\n     5 \u2524\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n       10:00              16:00\n</code></pre> <p>Pattern:  - Pelion: Sudden jump (physically impossible) - Neighbors: Smooth, gradual changes (normal weather)</p>"},{"location":"examples/device-failure/#failure-mode-analysis","title":"Failure Mode Analysis","text":""},{"location":"examples/device-failure/#common-sensor-failure-patterns","title":"Common Sensor Failure Patterns","text":"Pattern Likely Cause Example Value Fixed value (99.0) Sensor disconnected 99.0, 999.9 Negative spikes Electrical interference -127, -999 Constant zero Power loss 0.0 Erratic jumps Loose connection 5 \u2192 99 \u2192 3 \u2192 105 <p>This case: Fixed at 99.0 \u2192 Sensor disconnected or failed</p>"},{"location":"examples/device-failure/#diagnostic-steps-for-technicians","title":"Diagnostic Steps for Technicians","text":"<ol> <li>Check physical connection: Sensor cable may be disconnected</li> <li>Inspect sensor housing: Water ingress? Damage?</li> <li>Test voltage: Proper power supply to sensor?</li> <li>Check datalogger: Error codes in station logs?</li> <li>Replace sensor: If steps 1-4 show no issue</li> </ol>"},{"location":"examples/device-failure/#what-would-happen-without-spatial-verification","title":"What Would Happen Without Spatial Verification?","text":"<pre><code># Without --spatial-verify\npython anomaly_detector.py \\\n  --end \"2025-11-18 16:00:00\" \\\n  --temporal-method arima\n</code></pre> <p>Result:</p> <pre><code>Anomaly Breakdown:\n  \ud83d\udd34 Device Failures: 1      &lt;-- Still flagged, but no confirmation\n  \ud83c\udf27\ufe0f Weather Events: 0\n  \u26a0\ufe0f Suspected: 0\n</code></pre> <p>Problem:  - Without spatial verification, we can't be confident - Could it be an extreme microclimate event? - Could it be a wildfire nearby?</p> <p>With spatial verification:  - \u2705 Confirmed as device failure (neighbors normal) - \u2705 High confidence \u2192 immediate technician dispatch - \u2705 No false investigation of \"extreme weather\"</p>"},{"location":"examples/device-failure/#real-world-impact","title":"Real-World Impact","text":""},{"location":"examples/device-failure/#before-dual-verification","title":"Before Dual-Verification","text":"<pre><code>Operator receives alert \u2192 Checks weather reports \u2192 Sees clear skies \u2192 \nStill uncertain if it's sensor or real \u2192 Waits for more data \u2192 \nSensor remains broken for hours/days\n</code></pre>"},{"location":"examples/device-failure/#after-dual-verification","title":"After Dual-Verification","text":"<pre><code>System reports \"Device Failure\" \u2192 Operator immediately dispatches technician \u2192 \nSensor replaced within 4 hours \u2192 Data integrity restored\n</code></pre> <p>Time saved: ~24 hours False investigations: 0</p>"},{"location":"examples/device-failure/#alert-message","title":"Alert Message","text":""},{"location":"examples/device-failure/#email-alert-example","title":"Email Alert (Example)","text":"<pre><code>Subject: \ud83d\udd34 URGENT - Device Failure Detected at Pelion Station\n\nStation: pelion (Pelion Mountain)\nVariable: Temperature (temp_out)\nTimestamp: 2025-11-18 16:00:00\n\nAnomaly Details:\n  - Expected: 5.2\u00b0C\n  - Actual: 99.0\u00b0C\n  - Deviation: +93.8\u00b0C\n\nSpatial Verification:\n  - Correlation with neighbors: 0.05 (very low)\n  - Neighbors checked: zagora, volos\n  - Neighbor status: All normal\n\nClassification: DEVICE FAILURE (High Confidence)\n\nAction Required:\n  \u2610 Dispatch technician to Pelion station\n  \u2610 Check temperature sensor connection\n  \u2610 Inspect for physical damage\n  \u2610 Replace sensor if necessary\n\nDashboard: https://dashboard.example.com/stations/pelion\nReport: /var/log/weather/reports/report_20251118_160000.json\n</code></pre>"},{"location":"examples/device-failure/#comparison-weather-event-vs-device-failure","title":"Comparison: Weather Event vs Device Failure","text":"Characteristic Weather Event Device Failure Affected Stations Multiple (\u22653) Single (1) Spatial Correlation High (&gt;0.6) Low (&lt;0.3) Value Plausibility Realistic Often unrealistic Neighbor Behavior Similar pattern Normal/different Temporal Pattern Gradual change Sudden jump Action Required None Dispatch technician"},{"location":"examples/device-failure/#example-values","title":"Example Values","text":"<pre><code>Weather Event:\n  Station A: 15\u00b0C \u2192 10\u00b0C (gradual drop)\n  Station B: 16\u00b0C \u2192 11\u00b0C (gradual drop)\n  Station C: 14\u00b0C \u2192 9\u00b0C  (gradual drop)\n  Correlation: 0.89 \u2705\n\nDevice Failure:\n  Station A: 5\u00b0C \u2192 99\u00b0C  (sudden jump)\n  Station B: 8\u00b0C \u2192 8\u00b0C   (stable)\n  Station C: 11\u00b0C \u2192 11\u00b0C (stable)\n  Correlation: 0.05 \u274c\n</code></pre>"},{"location":"examples/device-failure/#post-incident-analysis","title":"Post-Incident Analysis","text":""},{"location":"examples/device-failure/#technician-report-example","title":"Technician Report (Example)","text":"<pre><code>Date: 2025-11-18\nStation: Pelion Mountain\nIssue: Temperature sensor failure\n\nFindings:\n  - Sensor cable disconnected from datalogger\n  - Cable connection corroded due to moisture\n  - Sensor itself functional when tested separately\n\nActions Taken:\n  - Cleaned and reconnected cable\n  - Applied dielectric grease to prevent corrosion\n  - Verified readings: Now reporting 5.3\u00b0C (expected for altitude)\n  - Added cable strain relief\n\nPreventive Measures:\n  - Schedule quarterly inspections of cable connections\n  - Consider upgrading to sealed waterproof connectors\n</code></pre>"},{"location":"examples/device-failure/#validation-after-repair","title":"Validation After Repair","text":"<pre><code># Run detection again after repair\npython anomaly_detector.py \\\n  --end \"2025-11-18 18:00:00\" \\\n  --spatial-verify\n</code></pre> <p>Result:</p> <pre><code>Total Stations: 14\nAnomalous Stations: 0\nNormal Stations: 14\n\n\u2705 All stations operating normally\n</code></pre>"},{"location":"examples/device-failure/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Low correlation (&lt;0.3) = Device failure - Strong indicator of isolated issue</li> <li>Unrealistic values - 99\u00b0C at mountain station is physically impossible</li> <li>Spatial verification provides confidence - Enables immediate action without doubt</li> <li>Typical failure mode - Fixed value (99.0) suggests disconnected sensor</li> <li>Quick resolution - Clear classification \u2192 fast technician dispatch \u2192 rapid fix</li> </ol>"},{"location":"examples/device-failure/#related-examples","title":"Related Examples","text":"<ul> <li>Weather Event Example - Contrasting case with high correlation</li> <li>Detection Methods - How ARIMA detected the anomaly</li> <li>Station Network - Understanding neighbor relationships</li> </ul>"},{"location":"examples/weather-event/","title":"Weather Event Example","text":""},{"location":"examples/weather-event/#scenario-cold-front-passing-through","title":"Scenario: Cold Front Passing Through","text":""},{"location":"examples/weather-event/#context","title":"Context","text":"<p>On November 20, 2025, a cold front moved through central Greece, causing temperatures to drop sharply across multiple stations.</p>"},{"location":"examples/weather-event/#detection-run","title":"Detection Run","text":"<pre><code>python anomaly_detector.py \\\n  --end \"2025-11-20 14:00:00\" \\\n  --window 6 \\\n  --temporal-method arima \\\n  --spatial-verify\n</code></pre>"},{"location":"examples/weather-event/#console-output","title":"Console Output","text":"<pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n ANOMALY DETECTION REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nEnd Time: 2025-11-20 14:00:00\nWindow: 6 hours\nMethod: arima\nSpatial Verification: Enabled\n\nTotal Stations: 14\nAnomalous Stations: 4\nNormal Stations: 10\n\nAnomaly Breakdown:\n  \ud83d\udd34 Device Failures: 0      &lt;-- \u2705 No hardware issues\n  \ud83c\udf27\ufe0f Weather Events: 4       &lt;-- 4 stations affected by cold front\n  \u26a0\ufe0f Suspected: 0\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n DETAILED REPORTS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[ STATION: uth_volos (Volos - University) ]\n  \u26a0\ufe0f  Temperature Anomaly:\n      Method: arima\n      Expected: 15.2\u00b0C | Actual: 10.1\u00b0C\n      \u2022 2025-11-20 14:00:00: 10.10\u00b0C -&gt; \ud83c\udf27\ufe0f Extreme Weather / Env Change\n        \u2514\u2500 Diag: Trend Consistent (Corr: 0.89, 3 neighbors)\n\n[ STATION: volos (Volos City) ]\n  \u26a0\ufe0f  Temperature Anomaly:\n      Method: arima\n      Expected: 15.5\u00b0C | Actual: 10.3\u00b0C\n      \u2022 2025-11-20 14:00:00: 10.30\u00b0C -&gt; \ud83c\udf27\ufe0f Extreme Weather / Env Change\n        \u2514\u2500 Diag: Trend Consistent (Corr: 0.92, 4 neighbors)\n\n[ STATION: zagora (Zagora) ]\n  \u26a0\ufe0f  Temperature Anomaly:\n      Method: arima\n      Expected: 12.8\u00b0C | Actual: 8.2\u00b0C\n      \u2022 2025-11-20 14:00:00: 8.20\u00b0C -&gt; \ud83c\udf27\ufe0f Extreme Weather / Env Change\n        \u2514\u2500 Diag: Trend Consistent (Corr: 0.87, 2 neighbors)\n\n[ STATION: larissa (Larissa) ]\n  \u26a0\ufe0f  Temperature Anomaly:\n      Method: arima\n      Expected: 16.1\u00b0C | Actual: 11.4\u00b0C\n      \u2022 2025-11-20 14:00:00: 11.40\u00b0C -&gt; \ud83c\udf27\ufe0f Extreme Weather / Env Change\n        \u2514\u2500 Diag: Trend Consistent (Corr: 0.91, 4 neighbors)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n NEIGHBOR COMPARISON - Station: uth_volos\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTime                 | uth_volos | volos | zagora | larissa\n---------------------|-----------|-------|--------|--------\n2025-11-20 08:00:00  | 15.2      | 15.5  | 12.8   | 16.1\n2025-11-20 08:30:00  | 15.1      | 15.4  | 12.7   | 16.0\n2025-11-20 09:00:00  | 14.8      | 15.2  | 12.5   | 15.8\n2025-11-20 09:30:00  | 14.4      | 14.9  | 12.1   | 15.4\n2025-11-20 10:00:00  | 13.9      | 14.4  | 11.6   | 14.9\n2025-11-20 10:30:00  | 13.2      | 13.7  | 10.9   | 14.2\n2025-11-20 11:00:00  | 12.4      | 12.9  | 10.1   | 13.4\n2025-11-20 11:30:00  | 11.6      | 12.1  | 9.4    | 12.7\n2025-11-20 12:00:00  | 11.0      | 11.4  | 8.8    | 12.1\n2025-11-20 12:30:00  | 10.5      | 10.9  | 8.5    | 11.7\n2025-11-20 13:00:00  | 10.3      | 10.6  | 8.3    | 11.5\n2025-11-20 13:30:00  | 10.2      | 10.4  | 8.2    | 11.4\n2025-11-20 14:00:00  | 10.1 \u26a0\ufe0f   | 10.3  | 8.2    | 11.4\n\nObservation: All stations show synchronized temperature drops\n\u2192 Classification: Weather Event (Cold Front)\n</code></pre>"},{"location":"examples/weather-event/#analysis","title":"Analysis","text":""},{"location":"examples/weather-event/#why-was-this-classified-as-weather-event","title":"Why Was This Classified as Weather Event?","text":"<ol> <li>Multiple Stations Affected: 4 out of 14 stations showed anomalies</li> <li>High Spatial Correlation: Average correlation = 0.90 (&gt; 0.6 threshold)</li> <li>Synchronized Timing: All anomalies occurred at the same timestamp</li> <li>Similar Magnitude: All stations dropped 4-5\u00b0C from expected</li> </ol>"},{"location":"examples/weather-event/#spatial-correlation-details","title":"Spatial Correlation Details","text":"<pre><code>Station Pair         | Correlation | Distance\n---------------------|-------------|----------\nuth_volos \u2194 volos    | 0.98        | 3.2 km\nuth_volos \u2194 zagora   | 0.87        | 28.5 km\nuth_volos \u2194 larissa  | 0.82        | 62.4 km\nvolos \u2194 larissa      | 0.94        | 65.1 km\n</code></pre> <p>All pairs show high correlation \u2192 Indicates regional weather pattern</p>"},{"location":"examples/weather-event/#time-series-visualization","title":"Time Series Visualization","text":""},{"location":"examples/weather-event/#temperature-trend-6-hour-window","title":"Temperature Trend (6-hour window)","text":"<pre><code>Temp (\u00b0C)\n    17 \u2524\n    16 \u2524\u25cf\u2500\u2500\u2500\u256e\n    15 \u2524    \u2570\u2500\u2500\u256e\n    14 \u2524       \u2570\u2500\u2500\u256e\n    13 \u2524          \u2570\u2500\u2500\u256e\n    12 \u2524             \u2570\u2500\u2500\u256e\n    11 \u2524                \u2570\u2500\u2500\u256e\n    10 \u2524                   \u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf \u2190 Anomaly detected\n     9 \u2524\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n       08:00              14:00\n</code></pre> <p>Pattern: Smooth, consistent decline (typical of cold front passage)</p>"},{"location":"examples/weather-event/#what-would-happen-without-spatial-verification","title":"What Would Happen Without Spatial Verification?","text":"<pre><code># Without --spatial-verify flag\npython anomaly_detector.py \\\n  --end \"2025-11-20 14:00:00\" \\\n  --temporal-method arima\n</code></pre> <p>Result: All 4 stations would be flagged as potential failures!</p> <pre><code>Anomaly Breakdown:\n  \ud83d\udd34 Device Failures: 4      &lt;-- \u274c FALSE ALARMS!\n  \ud83c\udf27\ufe0f Weather Events: 0\n  \u26a0\ufe0f Suspected: 0\n</code></pre> <p>Impact: Operations team would waste time investigating 4 \"failures\" that are actually normal weather.</p>"},{"location":"examples/weather-event/#meteorological-context","title":"Meteorological Context","text":""},{"location":"examples/weather-event/#cold-front-characteristics","title":"Cold Front Characteristics","text":"<ul> <li>Front Speed: ~30 km/h</li> <li>Temperature Drop: 5\u00b0C over 6 hours</li> <li>Affected Radius: ~100 km</li> <li>Duration: 8-12 hours</li> </ul>"},{"location":"examples/weather-event/#station-positions-relative-to-front","title":"Station Positions Relative to Front","text":"<pre><code>       N\n       \u2191\n   zagora \u25cf\n\nlarissa \u25cf \u2190 \u2190 [COLD FRONT] \u2192 \u2192 \u2192 uth_volos \u25cf\n                                            volos \u25cf\n</code></pre> <p>Front moved from west (larissa) to east (volos), causing sequential temperature drops.</p>"},{"location":"examples/weather-event/#actionable-insights","title":"Actionable Insights","text":""},{"location":"examples/weather-event/#for-operations-teams","title":"For Operations Teams","text":"<p>\u2705 No action required - This is normal weather</p>"},{"location":"examples/weather-event/#for-meteorologists","title":"For Meteorologists","text":"<ul> <li>Cold front passage confirmed by sensor network</li> <li>Front speed: ~30 km/h</li> <li>Can be used to validate weather models</li> </ul>"},{"location":"examples/weather-event/#for-researchers","title":"For Researchers","text":"<ul> <li>Example of successful dual-verification</li> <li>Spatial correlation accurately distinguished weather from failure</li> <li>System prevented 4 false alarm notifications</li> </ul>"},{"location":"examples/weather-event/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Spatial verification is critical - Reduced false positives from 4 to 0</li> <li>High correlation (&gt; 0.6) = Weather event - Multiple stations show similar patterns</li> <li>Distance doesn't matter much - Stations 60km apart still show 0.82 correlation</li> <li>ARIMA detected the anomaly - But spatial verification classified it correctly</li> </ol>"},{"location":"examples/weather-event/#related-examples","title":"Related Examples","text":"<ul> <li>Device Failure Example - Contrasting case with low correlation</li> <li>Detection Methods - Technical details on ARIMA</li> <li>Station Network - Map of station locations</li> </ul>"},{"location":"overview/features/","title":"Key Features","text":""},{"location":"overview/features/#dual-verification-strategy","title":"Dual-Verification Strategy","text":"<p>The core innovation of this system is its ability to distinguish between device failures and extreme weather events through a two-step verification process.</p>"},{"location":"overview/features/#why-this-matters","title":"Why This Matters","text":"<p>Traditional anomaly detection systems generate numerous false alarms when extreme weather events occur, because they cannot distinguish between:</p> <ul> <li>Genuine Equipment Failure: Only one station is malfunctioning</li> <li>Extreme Weather Event: Multiple stations show similar anomalous patterns</li> </ul> <p>Our dual-verification approach solves this by combining:</p> <ol> <li>Temporal Analysis (Self-Check): \"Is this station behaving differently than usual?\"</li> <li>Spatial Verification (Neighbor-Check): \"Are nearby stations behaving similarly?\"</li> </ol>"},{"location":"overview/features/#multi-method-detection","title":"Multi-Method Detection","text":"<p>The system supports seven different temporal detection algorithms:</p> Method Best For Computational Cost ARIMA Complex trends, seasonal patterns High 3-Sigma Quick outlier detection Low MAD Robust to outliers Medium IQR Exploratory analysis Low Isolation Forest Multidimensional patterns High STL Strong seasonality High LOF Density-based outliers Medium <p>Recommended Method</p> <p>For weather data, ARIMA provides the best balance between accuracy and false alarm reduction.</p>"},{"location":"overview/features/#real-time-processing","title":"Real-Time Processing","text":""},{"location":"overview/features/#streaming-architecture","title":"Streaming Architecture","text":"<ul> <li>Ingestion Frequency: Data collected every 10 minutes</li> <li>Detection Window: Configurable (default: 6 hours)</li> <li>Sliding Stride: Moves forward with each new data point</li> <li>Latency: Near real-time detection (&lt; 1 minute processing time)</li> </ul>"},{"location":"overview/features/#memory-efficiency","title":"Memory Efficiency","text":"<p>The sliding window mechanism ensures:</p> <ul> <li>Constant Memory Usage: O(1) regardless of database size</li> <li>Fast Query Performance: Only queries relevant time ranges</li> <li>Scalable Storage: Old data remains accessible but not loaded into memory</li> </ul>"},{"location":"overview/features/#spatial-intelligence","title":"Spatial Intelligence","text":""},{"location":"overview/features/#neighbor-detection","title":"Neighbor Detection","text":"<p>The system automatically:</p> <ol> <li>Calculates distances between all station pairs</li> <li>Identifies neighbors within 100km radius</li> <li>Computes correlation coefficients during anomalies</li> <li>Interpolates missing data to ensure robust comparison</li> </ol>"},{"location":"overview/features/#correlation-thresholds","title":"Correlation Thresholds","text":"Correlation Interpretation Action &gt; 0.6 High correlation - Weather event Ignore 0.3 - 0.6 Uncertain - Requires manual review Flag as \"Suspected\" &lt; 0.3 Low correlation - Device failure Alert <p>Missing Data Handling</p> <p>When neighbor data has gaps, the system uses linear interpolation to fill missing values before computing correlations.</p>"},{"location":"overview/features/#scalable-database-backend","title":"Scalable Database Backend","text":""},{"location":"overview/features/#sqlite-mode-default","title":"SQLite Mode (Default)","text":"<p>Perfect for:</p> <ul> <li>Standalone deployment</li> <li>Development and testing</li> <li>Single-server installations</li> <li>&lt; 100 stations</li> </ul>"},{"location":"overview/features/#timescaledb-mode-enterprise","title":"TimescaleDB Mode (Enterprise)","text":"<p>Recommended for:</p> <ul> <li>Multi-server deployment</li> <li> <p>100 stations</p> </li> <li>Years of historical data</li> <li>Advanced analytics queries</li> </ul> <p>Migration between backends requires minimal code changes - only the connection string needs updating.</p>"},{"location":"overview/features/#interactive-visualization","title":"Interactive Visualization","text":"<p>The system generates:</p> <ul> <li>Station Network Maps: Interactive HTML maps showing station locations and neighbor connections</li> <li>Anomaly Reports: JSON format for integration with monitoring dashboards</li> <li>Console Output: Human-readable summaries for manual inspection</li> </ul> <p>View an example: Station Network Map</p>"},{"location":"overview/features/#api-first-design","title":"API-First Design","text":"<p>While currently used as a command-line tool, the detection engine is designed with clear interfaces:</p> <ul> <li>Input: Time window + detection parameters</li> <li>Output: Structured anomaly reports</li> <li>Future-ready: Can be easily wrapped in a REST API</li> </ul>"},{"location":"overview/features/#extensibility","title":"Extensibility","text":"<p>Adding new features is straightforward:</p> <ul> <li>New Detection Methods: Implement the <code>TemporalDetector</code> interface</li> <li>New Variables: Add to the database schema and detector configuration</li> <li>New Spatial Methods: Extend the <code>SpatialVerifier</code> class</li> <li>New Data Sources: Replace the collector module</li> </ul>"},{"location":"overview/how-it-works/","title":"How It Works","text":""},{"location":"overview/how-it-works/#overall-workflow","title":"Overall Workflow","text":"<pre><code>flowchart TD\n    A[Start Detection] --&gt; B[Query Data Window]\n    B --&gt; C[For Each Station]\n    C --&gt; D{Temporal Check}\n    D --&gt;|Normal| E[Mark as Normal]\n    D --&gt;|Anomalous| F{Spatial Verify Enabled?}\n    F --&gt;|No| G[Report as Anomaly]\n    F --&gt;|Yes| H[Find Neighbors]\n    H --&gt; I[Compute Correlations]\n    I --&gt; J{Correlation Level?}\n    J --&gt;|High &gt; 0.6| K[Weather Event]\n    J --&gt;|Medium 0.3-0.6| L[Suspected - Manual Review]\n    J --&gt;|Low &lt; 0.3| M[Device Failure]\n    E --&gt; N[Generate Report]\n    G --&gt; N\n    K --&gt; N\n    L --&gt; N\n    M --&gt; N</code></pre>"},{"location":"overview/how-it-works/#step-1-temporal-detection","title":"Step 1: Temporal Detection","text":""},{"location":"overview/how-it-works/#purpose","title":"Purpose","text":"<p>Identify if a station's current reading deviates significantly from its own historical pattern.</p>"},{"location":"overview/how-it-works/#process","title":"Process","text":"<ol> <li>Query Historical Window: Retrieve the last N hours of data for the station (default: 6 hours)</li> <li>Fit Model: Train a time series model (e.g., ARIMA) on the historical data</li> <li>Predict Expected Value: Generate a forecast for the current timestamp</li> <li>Calculate Deviation: Compare actual vs. predicted value</li> <li>Flag Anomaly: If deviation exceeds threshold, mark as suspect</li> </ol>"},{"location":"overview/how-it-works/#example-arima-detection","title":"Example: ARIMA Detection","text":"<pre><code># Simplified example\nhistorical_data = query_window(station_id, hours=6)\nmodel = ARIMA(historical_data, order=(1,1,1))\nfitted_model = model.fit()\n\npredicted = fitted_model.forecast(steps=1)\nactual = get_current_value(station_id)\n\nif abs(actual - predicted) &gt; threshold:\n    flag_as_anomaly(station_id, variable)\n</code></pre>"},{"location":"overview/how-it-works/#why-different-methods","title":"Why Different Methods?","text":"<p>Different algorithms work better for different scenarios:</p> <ul> <li>ARIMA: Best for data with trends and seasonality (weather)</li> <li>3-Sigma: Fast baseline for normally distributed data</li> <li>MAD: Robust when data contains outliers</li> <li>Isolation Forest: Effective for multidimensional patterns</li> </ul>"},{"location":"overview/how-it-works/#step-2-spatial-verification","title":"Step 2: Spatial Verification","text":""},{"location":"overview/how-it-works/#purpose_1","title":"Purpose","text":"<p>Determine if the anomaly is localized (device failure) or widespread (weather event).</p>"},{"location":"overview/how-it-works/#process_1","title":"Process","text":"<ol> <li>Find Neighbors: Query all stations within 100km radius</li> <li>Retrieve Neighbor Data: Get the same time window for all neighbors</li> <li>Handle Missing Data: Interpolate gaps to ensure robust comparison</li> <li>Compute Trend Correlation: Calculate Pearson correlation on the past 6 hours</li> <li>Classify Anomaly:</li> <li>High correlation (&gt; 0.6): Neighbors show same trend \u2192 Weather event</li> <li>Low correlation (&lt; 0.3): Only this station is anomalous \u2192 Device failure</li> <li>Medium correlation (0.3-0.6): Uncertain \u2192 Requires manual review</li> </ol>"},{"location":"overview/how-it-works/#example-scenarios","title":"Example Scenarios","text":""},{"location":"overview/how-it-works/#scenario-a-extreme-weather-event","title":"Scenario A: Extreme Weather Event","text":"<pre><code>Station A: Temperature drops from 15\u00b0C to 5\u00b0C (flagged)\nStation B (50km away): Temperature drops from 16\u00b0C to 6\u00b0C\nStation C (80km away): Temperature drops from 14\u00b0C to 4\u00b0C\n\n\u2192 High correlation (0.85)\n\u2192 Classification: Weather Event (Ignore)\n</code></pre>"},{"location":"overview/how-it-works/#scenario-b-device-failure","title":"Scenario B: Device Failure","text":"<pre><code>Station A: Temperature shows 99\u00b0C (flagged)\nStation B (50km away): Temperature stable at 15\u00b0C\nStation C (80km away): Temperature stable at 14\u00b0C\n\n\u2192 Low correlation (0.05)\n\u2192 Classification: Device Failure (Alert!)\n</code></pre>"},{"location":"overview/how-it-works/#why-pearson-correlation","title":"Why Pearson Correlation?","text":"<p>Pearson correlation measures trend consistency, not absolute value similarity:</p> <ul> <li>Two stations can have different base temperatures but move together</li> <li>Example: Station A at 10\u00b0C drops to 8\u00b0C, Station B at 15\u00b0C drops to 13\u00b0C   \u2192 Both drop by 2\u00b0C \u2192 High correlation</li> </ul>"},{"location":"overview/how-it-works/#data-collection-pipeline","title":"Data Collection Pipeline","text":""},{"location":"overview/how-it-works/#collector-daemon","title":"Collector Daemon","text":"<pre><code>sequenceDiagram\n    participant Timer\n    participant Collector\n    participant API as NOA API\n    participant DB as Database\n\n    loop Every 10 minutes\n        Timer-&gt;&gt;Collector: Trigger collection\n        Collector-&gt;&gt;API: GET latestValues.geojson\n        API--&gt;&gt;Collector: Return station data\n        Collector-&gt;&gt;Collector: Parse GeoJSON\n        Collector-&gt;&gt;DB: INSERT new observations\n        Collector-&gt;&gt;Collector: Log success\n    end</code></pre>"},{"location":"overview/how-it-works/#database-storage","title":"Database Storage","text":"<p>Data is stored with a composite primary key to ensure uniqueness:</p> <pre><code>CREATE TABLE observations (\n    time TIMESTAMP,\n    station_id TEXT,\n    temp_out REAL,\n    out_hum REAL,\n    wind_speed REAL,\n    bar REAL,\n    rain REAL,\n    PRIMARY KEY (time, station_id)\n);\n\n-- Optimized index for time-range queries\nCREATE INDEX idx_time ON observations(time DESC);\n</code></pre>"},{"location":"overview/how-it-works/#sliding-window-mechanism","title":"Sliding Window Mechanism","text":""},{"location":"overview/how-it-works/#why-sliding-windows","title":"Why Sliding Windows?","text":"<p>Traditional batch processing loads all historical data into memory:</p> <ul> <li>Problem: Memory usage grows linearly with data size</li> <li>Result: System becomes slower over time</li> </ul> <p>Sliding windows only load the relevant time range:</p> <ul> <li>Advantage: Constant memory usage O(1)</li> <li>Result: Performance remains stable regardless of database size</li> </ul>"},{"location":"overview/how-it-works/#window-parameters","title":"Window Parameters","text":"Parameter Default Description Window Size 6 hours Amount of historical data to analyze Stride 10 minutes How far the window moves forward End Time NOW The current timestamp to detect"},{"location":"overview/how-it-works/#visualization","title":"Visualization","text":"<pre><code>Timeline:  [...............|======WINDOW======|*]\n                          6h ago          NOW (*)\n                                          \u2193\n                                    Detection Point\n\nEach window:\n- Analyzes data from [NOW-6h] to [NOW]\n- Predicts value at NOW\n- Compares with actual value at NOW\n</code></pre>"},{"location":"overview/how-it-works/#output-format","title":"Output Format","text":""},{"location":"overview/how-it-works/#console-report","title":"Console Report","text":"<pre><code>\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n ANOMALY DETECTION REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTotal Stations: 14\nAnomalous Stations: 1\nNormal Stations: 13\n\nAnomaly Breakdown:\n  \ud83d\udd34 Device Failures: 1      &lt;- Action required\n  \ud83c\udf27\ufe0f Weather Events: 0       &lt;- No action needed\n  \u26a0\ufe0f Suspected: 0            &lt;- Manual review\n\n[ STATION: uth_volos ]\n  \ud83d\udd34 Temperature Anomaly:\n      Method: arima\n      Expected: 12.5\u00b0C | Actual: 25.8\u00b0C\n      \u2022 2025-11-22 17:00:00: 25.80\u00b0C -&gt; \ud83d\udd34 Device Failure\n        \u2514\u2500 Diag: Trend Inconsistent (Corr: 0.12, 3 neighbors)\n</code></pre>"},{"location":"overview/how-it-works/#json-report-optional","title":"JSON Report (Optional)","text":"<pre><code>{\n  \"timestamp\": \"2025-11-22T17:00:00Z\",\n  \"total_stations\": 14,\n  \"anomalous_stations\": 1,\n  \"device_failures\": 1,\n  \"weather_events\": 0,\n  \"suspected\": 0,\n  \"details\": [\n    {\n      \"station_id\": \"uth_volos\",\n      \"variable\": \"temp_out\",\n      \"method\": \"arima\",\n      \"expected\": 12.5,\n      \"actual\": 25.8,\n      \"classification\": \"device_failure\",\n      \"spatial_correlation\": 0.12,\n      \"neighbors_checked\": 3\n    }\n  ]\n}\n</code></pre>"},{"location":"overview/how-it-works/#performance-characteristics","title":"Performance Characteristics","text":"Metric Value Notes Detection Latency &lt; 1 minute For 14 stations with ARIMA Memory Usage ~200MB Constant regardless of DB size Database Size ~10MB/month For 14 stations at 10-min intervals Scalability Linear Scales with number of stations, not time"},{"location":"setup/configuration/","title":"Configuration","text":""},{"location":"setup/configuration/#overview","title":"Overview","text":"<p>The Real-Time Anomaly Detection system can be configured through:</p> <ol> <li>Command-line arguments (highest priority)</li> <li>Environment variables</li> <li>Default values (lowest priority)</li> </ol>"},{"location":"setup/configuration/#collector-configuration","title":"Collector Configuration","text":""},{"location":"setup/configuration/#data-source","title":"Data Source","text":"<p>The collector fetches data from the NOA API:</p> <p>Default URL: <code>https://stratus.meteo.noa.gr/data/stations/latestValues_Datagems.geojson</code></p> <p>To use a different data source, edit <code>streaming_collector_sqlite.py</code>:</p> <pre><code># Change this line\nAPI_URL = \"https://your-custom-api.example.com/data.geojson\"\n</code></pre>"},{"location":"setup/configuration/#collection-interval","title":"Collection Interval","text":"<p>Default: 10 minutes</p> <p>To change the interval, edit <code>streaming_collector_sqlite.py</code>:</p> <pre><code># Change this value (in seconds)\nCOLLECTION_INTERVAL = 600  # 10 minutes\n</code></pre> <p>Recommendations:</p> Interval Use Case Disk Usage 5 min High-resolution monitoring 20MB/month 10 min Default (balanced) 10MB/month 30 min Low-frequency monitoring 3MB/month 60 min Historical trends only 1.5MB/month <p>API Rate Limits</p> <p>The NOA API updates every 10 minutes. Setting intervals &lt; 10 minutes will fetch duplicate data.</p>"},{"location":"setup/configuration/#database-path","title":"Database Path","text":"<p>Default: <code>weather_stream.db</code> (current directory)</p> <p>To change:</p> <pre><code># Option 1: Edit streaming_collector_sqlite.py\nDATABASE_PATH = \"/var/lib/weather/stream.db\"\n\n# Option 2: Use environment variable\nexport WEATHER_DB=\"/var/lib/weather/stream.db\"\npython streaming_collector_sqlite.py\n</code></pre>"},{"location":"setup/configuration/#detector-configuration","title":"Detector Configuration","text":""},{"location":"setup/configuration/#default-parameters","title":"Default Parameters","text":"<p>Create a configuration file for convenience:</p> <pre><code># config.env\nexport DETECTION_METHOD=\"arima\"\nexport DETECTION_WINDOW=6\nexport SPATIAL_VERIFY=1\nexport NEIGHBOR_RADIUS=100\nexport DATABASE_PATH=\"weather_stream.db\"\n</code></pre> <p>Load before running:</p> <pre><code>source config.env\npython anomaly_detector.py --end \"NOW\"\n</code></pre>"},{"location":"setup/configuration/#detection-method","title":"Detection Method","text":"<p>Default: ARIMA</p> <p>To change default, edit <code>anomaly_detector.py</code>:</p> <pre><code>parser.add_argument('--temporal-method', default='arima', ...)\n</code></pre> <p>Method Selection Matrix:</p> Scenario Recommended Method Production (accuracy) arima Testing (speed) 3sigma Noisy data mad Exploratory iqr Multidimensional isolation_forest"},{"location":"setup/configuration/#window-size","title":"Window Size","text":"<p>Default: 6 hours</p> <p>Adjust based on data patterns:</p> <pre><code># Short-term anomalies (sensor glitches)\n--window 1\n\n# Standard weather patterns (recommended)\n--window 6\n\n# Daily cycles (temperature, humidity)\n--window 24\n\n# Multi-day trends\n--window 48\n</code></pre>"},{"location":"setup/configuration/#spatial-verification","title":"Spatial Verification","text":"<p>Default: Disabled (for backward compatibility)</p> <p>Recommendation: Always enable in production</p> <pre><code># Enable (recommended)\npython anomaly_detector.py --spatial-verify\n\n# Disable (testing only)\npython anomaly_detector.py\n</code></pre>"},{"location":"setup/configuration/#correlation-thresholds","title":"Correlation Thresholds","text":"<p>Defaults:</p> <ul> <li>High threshold: 0.6 (weather event)</li> <li>Low threshold: 0.3 (device failure)</li> </ul> <p>Tune based on your environment:</p> <pre><code># More strict (fewer weather events)\n--correlation-threshold-high 0.7 \\\n--correlation-threshold-low 0.2\n\n# More lenient (more weather events)\n--correlation-threshold-high 0.5 \\\n--correlation-threshold-low 0.4\n</code></pre> <p>Effect:</p> <pre><code>High = 0.7, Low = 0.3:\n  [0.0 - 0.3): Device Failure\n  [0.3 - 0.7): Suspected\n  [0.7 - 1.0]: Weather Event\n\nHigh = 0.6, Low = 0.3 (default):\n  [0.0 - 0.3): Device Failure\n  [0.3 - 0.6): Suspected\n  [0.6 - 1.0]: Weather Event\n</code></pre>"},{"location":"setup/configuration/#neighbor-radius","title":"Neighbor Radius","text":"<p>Default: 100 km</p> <p>Adjust based on terrain:</p> Terrain Type Recommended Radius Reason Flat plains 100-150 km Weather systems move uniformly Mountains 50-75 km Microclimates Coastal 75-100 km Land-sea interaction Urban 50 km Heat islands Sparse network 150-200 km Need enough neighbors <pre><code># Mountain region\n--neighbor-radius 50\n\n# Flat plains\n--neighbor-radius 150\n</code></pre>"},{"location":"setup/configuration/#station-configuration","title":"Station Configuration","text":""},{"location":"setup/configuration/#station-metadata","title":"Station Metadata","text":"<p>Station information is automatically fetched from the NOA API. To manually override, create <code>stations.json</code>:</p> <pre><code>{\n  \"uth_volos\": {\n    \"name\": \"University of Thessaly - Volos\",\n    \"lat\": 39.3636,\n    \"lon\": 22.9530,\n    \"elevation\": 15,\n    \"enabled\": true\n  },\n  \"volos\": {\n    \"name\": \"Volos City Center\",\n    \"lat\": 39.3620,\n    \"lon\": 22.9467,\n    \"elevation\": 5,\n    \"enabled\": true\n  }\n}\n</code></pre>"},{"location":"setup/configuration/#disabling-stations","title":"Disabling Stations","text":"<p>To exclude specific stations from analysis:</p> <pre><code># Edit anomaly_detector.py\nEXCLUDED_STATIONS = ['metsovo', 'preveza']  # Isolated stations\n</code></pre> <p>Or use command-line filter (future feature):</p> <pre><code>python anomaly_detector.py --exclude-stations \"metsovo,preveza\"\n</code></pre>"},{"location":"setup/configuration/#variable-configuration","title":"Variable Configuration","text":""},{"location":"setup/configuration/#enabled-variables","title":"Enabled Variables","text":"<p>Default: All variables (temp_out, out_hum, wind_speed, bar, rain)</p> <p>To analyze specific variables only:</p> <pre><code># Temperature only\npython anomaly_detector.py --variables \"temp_out\"\n\n# Temperature and pressure\npython anomaly_detector.py --variables \"temp_out,bar\"\n</code></pre>"},{"location":"setup/configuration/#variable-specific-thresholds","title":"Variable-Specific Thresholds","text":"<p>For advanced tuning, edit the detector configuration:</p> <pre><code># In anomaly_detector.py\nVARIABLE_THRESHOLDS = {\n    'temp_out': {'method': 'arima', 'threshold': 0.95},\n    'out_hum': {'method': 'arima', 'threshold': 0.90},\n    'wind_speed': {'method': 'mad', 'threshold': 4.0},\n    'bar': {'method': '3sigma', 'threshold': 3.0},\n    'rain': {'method': 'iqr', 'threshold': 1.5}\n}\n</code></pre> <p>Rationale:</p> <ul> <li>Temperature: Smooth trends \u2192 ARIMA</li> <li>Humidity: Similar to temperature \u2192 ARIMA</li> <li>Wind Speed: Very volatile \u2192 MAD (robust)</li> <li>Pressure: Stable baseline \u2192 3-Sigma (fast)</li> <li>Rainfall: Sparse, many zeros \u2192 IQR</li> </ul>"},{"location":"setup/configuration/#logging-configuration","title":"Logging Configuration","text":""},{"location":"setup/configuration/#log-levels","title":"Log Levels","text":"<p>Default: INFO</p> <pre><code># In streaming_collector_sqlite.py or anomaly_detector.py\nimport logging\n\n# Change log level\nlogging.basicConfig(level=logging.DEBUG)  # Verbose\nlogging.basicConfig(level=logging.INFO)   # Default\nlogging.basicConfig(level=logging.WARNING) # Quiet\n</code></pre>"},{"location":"setup/configuration/#log-files","title":"Log Files","text":"<p>Default: Console output + <code>streaming_collector.log</code></p> <p>To customize:</p> <pre><code># In streaming_collector_sqlite.py\nLOG_FILE = \"/var/log/weather/collector.log\"\n\n# Add file handler\nfile_handler = logging.FileHandler(LOG_FILE)\nfile_handler.setLevel(logging.INFO)\nlogger.addHandler(file_handler)\n</code></pre>"},{"location":"setup/configuration/#log-rotation","title":"Log Rotation","text":"<p>For production, use <code>logrotate</code>:</p> <pre><code># Create /etc/logrotate.d/weather-collector\ncat &gt; /etc/logrotate.d/weather-collector &lt;&lt; 'EOF'\n/var/log/weather/*.log {\n    daily\n    rotate 7\n    compress\n    missingok\n    notifempty\n    create 0640 weather weather\n}\nEOF\n</code></pre>"},{"location":"setup/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"setup/configuration/#database-optimization","title":"Database Optimization","text":""},{"location":"setup/configuration/#sqlite-configuration","title":"SQLite Configuration","text":"<pre><code># In streaming_collector_sqlite.py\nconn = sqlite3.connect('weather_stream.db')\n\n# Enable WAL mode for better concurrency\nconn.execute('PRAGMA journal_mode=WAL')\n\n# Increase cache size (10MB)\nconn.execute('PRAGMA cache_size=-10000')\n\n# Synchronous mode (balance safety vs speed)\nconn.execute('PRAGMA synchronous=NORMAL')\n</code></pre>"},{"location":"setup/configuration/#vacuum-database-periodically","title":"Vacuum Database Periodically","text":"<pre><code># Add to cron (weekly)\n0 2 * * 0 sqlite3 /path/to/weather_stream.db 'VACUUM;'\n</code></pre>"},{"location":"setup/configuration/#memory-usage","title":"Memory Usage","text":"<p>Limit memory for large windows:</p> <pre><code># In anomaly_detector.py\nimport resource\n\n# Limit to 1GB\nresource.setrlimit(resource.RLIMIT_AS, (1024*1024*1024, 1024*1024*1024))\n</code></pre>"},{"location":"setup/configuration/#parallel-processing-future","title":"Parallel Processing (Future)","text":"<p>Enable multi-station parallel detection:</p> <pre><code># Future feature\npython anomaly_detector.py --end \"NOW\" --spatial-verify --parallel --workers 4\n</code></pre>"},{"location":"setup/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"setup/configuration/#database-permissions","title":"Database Permissions","text":"<pre><code># Restrict database access\nchmod 600 weather_stream.db\nchown weather:weather weather_stream.db\n</code></pre>"},{"location":"setup/configuration/#network-security","title":"Network Security","text":"<p>The collector uses HTTPS by default. To add authentication:</p> <pre><code># In streaming_collector_sqlite.py\nimport requests\n\n# Add authentication\nresponse = requests.get(API_URL, auth=('username', 'password'))\n</code></pre>"},{"location":"setup/configuration/#sandboxing","title":"Sandboxing","text":"<p>Run collector as limited user:</p> <pre><code># Create dedicated user\nsudo useradd -r -s /bin/false weather\n\n# Run as this user\nsudo -u weather python streaming_collector_sqlite.py\n</code></pre>"},{"location":"setup/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"setup/configuration/#development","title":"Development","text":"<pre><code># config_dev.env\nexport WEATHER_DB=\"dev_weather.db\"\nexport DETECTION_METHOD=\"3sigma\"  # Faster\nexport COLLECTION_INTERVAL=300    # 5 min for testing\nexport LOG_LEVEL=\"DEBUG\"\n</code></pre>"},{"location":"setup/configuration/#production","title":"Production","text":"<pre><code># config_prod.env\nexport WEATHER_DB=\"/var/lib/weather/stream.db\"\nexport DETECTION_METHOD=\"arima\"\nexport COLLECTION_INTERVAL=600    # 10 min\nexport LOG_LEVEL=\"INFO\"\nexport ENABLE_ALERTS=1\n</code></pre>"},{"location":"setup/configuration/#testing","title":"Testing","text":"<pre><code># config_test.env\nexport WEATHER_DB=\":memory:\"      # In-memory DB\nexport DETECTION_METHOD=\"3sigma\"\nexport LOG_LEVEL=\"WARNING\"\n</code></pre>"},{"location":"setup/configuration/#configuration-validation","title":"Configuration Validation","text":""},{"location":"setup/configuration/#validate-settings","title":"Validate Settings","text":"<pre><code>#!/usr/bin/env python3\n# validate_config.py\n\nimport sys\n\ndef validate_config():\n    errors = []\n\n    # Check database path\n    import os\n    if not os.access(os.path.dirname(DATABASE_PATH) or '.', os.W_OK):\n        errors.append(f\"Database path not writable: {DATABASE_PATH}\")\n\n    # Check collection interval\n    if COLLECTION_INTERVAL &lt; 60:\n        errors.append(f\"Collection interval too short: {COLLECTION_INTERVAL}s\")\n\n    # Check neighbor radius\n    if NEIGHBOR_RADIUS &lt; 10 or NEIGHBOR_RADIUS &gt; 500:\n        errors.append(f\"Neighbor radius out of range: {NEIGHBOR_RADIUS}km\")\n\n    if errors:\n        print(\"Configuration Errors:\")\n        for error in errors:\n            print(f\"  - {error}\")\n        sys.exit(1)\n    else:\n        print(\"\u2705 Configuration valid\")\n\nif __name__ == \"__main__\":\n    validate_config()\n</code></pre> <p>Run before deployment:</p> <pre><code>python validate_config.py\n</code></pre>"},{"location":"setup/configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"setup/configuration/#example-1-high-accuracy-production","title":"Example 1: High-Accuracy Production","text":"<pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --window 6 \\\n  --temporal-method arima \\\n  --spatial-verify \\\n  --neighbor-radius 100 \\\n  --correlation-threshold-high 0.6 \\\n  --correlation-threshold-low 0.3 \\\n  --save \"/var/log/anomaly_reports/report_$(date +%Y%m%d_%H%M%S).json\"\n</code></pre>"},{"location":"setup/configuration/#example-2-fast-testing","title":"Example 2: Fast Testing","text":"<pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --window 1 \\\n  --temporal-method 3sigma \\\n  --variables \"temp_out\"\n</code></pre>"},{"location":"setup/configuration/#example-3-conservative-few-false-alarms","title":"Example 3: Conservative (Few False Alarms)","text":"<pre><code>python anomaly_detector.py \\\n  --end \"NOW\" \\\n  --temporal-method arima \\\n  --temporal-threshold 0.99 \\\n  --spatial-verify \\\n  --correlation-threshold-high 0.7 \\\n  --correlation-threshold-low 0.2\n</code></pre> <p>For deployment-specific configurations, see Deployment Guide.</p>"},{"location":"setup/database/","title":"Database Options","text":""},{"location":"setup/database/#overview","title":"Overview","text":"<p>The system supports two database backends:</p> <ol> <li>SQLite (default) - For standalone deployments</li> <li>TimescaleDB - For enterprise scale</li> </ol>"},{"location":"setup/database/#sqlite-default","title":"SQLite (Default)","text":""},{"location":"setup/database/#advantages","title":"Advantages","text":"<ul> <li>\u2705 No external dependencies</li> <li>\u2705 Zero configuration</li> <li>\u2705 Single-file storage</li> <li>\u2705 Perfect for &lt; 100 stations</li> <li>\u2705 Embedded in Python</li> </ul>"},{"location":"setup/database/#limitations","title":"Limitations","text":"<ul> <li>\u26a0\ufe0f Single writer (sufficient for this use case)</li> <li>\u26a0\ufe0f Local storage only</li> <li>\u26a0\ufe0f Limited scalability</li> </ul>"},{"location":"setup/database/#configuration","title":"Configuration","text":"<pre><code># Default - no configuration needed\nDATABASE_PATH = \"weather_stream.db\"\n</code></pre>"},{"location":"setup/database/#performance-optimization","title":"Performance Optimization","text":"<pre><code>import sqlite3\n\nconn = sqlite3.connect('weather_stream.db')\n\n# Enable WAL mode for better concurrent reads\nconn.execute('PRAGMA journal_mode=WAL;')\n\n# Increase cache size (10MB)\nconn.execute('PRAGMA cache_size=-10000;')\n\n# Optimize synchronization\nconn.execute('PRAGMA synchronous=NORMAL;')\n\n# Enable memory-mapped I/O (64MB)\nconn.execute('PRAGMA mmap_size=67108864;')\n</code></pre>"},{"location":"setup/database/#maintenance","title":"Maintenance","text":"<pre><code># Vacuum database (reclaim space)\nsqlite3 weather_stream.db 'VACUUM;'\n\n# Analyze for query optimization\nsqlite3 weather_stream.db 'ANALYZE;'\n\n# Check integrity\nsqlite3 weather_stream.db 'PRAGMA integrity_check;'\n</code></pre>"},{"location":"setup/database/#timescaledb-enterprise","title":"TimescaleDB (Enterprise)","text":""},{"location":"setup/database/#when-to-use","title":"When to Use","text":"<p>Consider TimescaleDB when:</p> <ul> <li>\u2705 Monitoring &gt; 100 stations</li> <li>\u2705 Need distributed deployment</li> <li>\u2705 Require advanced analytics</li> <li>\u2705 Want automatic data compression</li> <li>\u2705 Need high availability</li> </ul>"},{"location":"setup/database/#installation","title":"Installation","text":""},{"location":"setup/database/#docker-recommended","title":"Docker (Recommended)","text":"<pre><code># Run TimescaleDB container\ndocker run -d \\\n    --name timescaledb \\\n    -p 5432:5432 \\\n    -e POSTGRES_PASSWORD=password \\\n    -v timescale-data:/var/lib/postgresql/data \\\n    timescale/timescaledb:latest-pg15\n</code></pre>"},{"location":"setup/database/#ubuntudebian","title":"Ubuntu/Debian","text":"<pre><code># Add repository\nsudo sh -c \"echo 'deb https://packagecloud.io/timescale/timescaledb/ubuntu/ $(lsb_release -c -s) main' &gt; /etc/apt/sources.list.d/timescaledb.list\"\n\n# Import GPG key\nwget --quiet -O - https://packagecloud.io/timescale/timescaledb/gpgkey | sudo apt-key add -\n\n# Install\nsudo apt update\nsudo apt install timescaledb-2-postgresql-15\n\n# Configure\nsudo timescaledb-tune --quiet --yes\n\n# Restart PostgreSQL\nsudo systemctl restart postgresql\n</code></pre>"},{"location":"setup/database/#database-setup","title":"Database Setup","text":"<pre><code>-- Create database\nCREATE DATABASE weather_monitoring;\n\n-- Connect\n\\c weather_monitoring\n\n-- Enable TimescaleDB extension\nCREATE EXTENSION IF NOT EXISTS timescaledb;\n\n-- Create table\nCREATE TABLE observations (\n    time TIMESTAMPTZ NOT NULL,\n    station_id TEXT NOT NULL,\n    temp_out REAL,\n    out_hum REAL,\n    wind_speed REAL,\n    bar REAL,\n    rain REAL\n);\n\n-- Convert to hypertable (enables time-series optimizations)\nSELECT create_hypertable('observations', 'time');\n\n-- Create indexes\nCREATE INDEX idx_station_time ON observations (station_id, time DESC);\nCREATE INDEX idx_time ON observations (time DESC);\n\n-- Add compression policy (compress data &gt; 7 days old)\nALTER TABLE observations SET (\n    timescaledb.compress,\n    timescaledb.compress_segmentby = 'station_id'\n);\n\nSELECT add_compression_policy('observations', INTERVAL '7 days');\n\n-- Add retention policy (drop data &gt; 1 year old)\nSELECT add_retention_policy('observations', INTERVAL '1 year');\n</code></pre>"},{"location":"setup/database/#application-configuration","title":"Application Configuration","text":"<p>Update connection string in collector and detector:</p> <pre><code># streaming_collector_timescale.py\nimport psycopg2\n\n# PostgreSQL/TimescaleDB connection\nconn = psycopg2.connect(\n    host=\"localhost\",\n    port=5432,\n    database=\"weather_monitoring\",\n    user=\"postgres\",\n    password=\"password\"\n)\n\n# Use same SQL as SQLite (mostly compatible)\ncursor = conn.cursor()\ncursor.execute(\"\"\"\n    INSERT INTO observations (time, station_id, temp_out, out_hum, wind_speed, bar, rain)\n    VALUES (%s, %s, %s, %s, %s, %s, %s)\n    ON CONFLICT (time, station_id) DO UPDATE SET\n        temp_out = EXCLUDED.temp_out,\n        out_hum = EXCLUDED.out_hum,\n        wind_speed = EXCLUDED.wind_speed,\n        bar = EXCLUDED.bar,\n        rain = EXCLUDED.rain\n\"\"\", (time, station_id, temp, hum, wind, bar, rain))\nconn.commit()\n</code></pre>"},{"location":"setup/database/#performance-tuning","title":"Performance Tuning","text":"<pre><code>-- Optimize query performance\nSET max_parallel_workers_per_gather = 4;\nSET work_mem = '256MB';\n\n-- Enable Just-In-Time compilation\nSET jit = on;\n\n-- Create materialized view for faster aggregations\nCREATE MATERIALIZED VIEW hourly_stats\nWITH (timescaledb.continuous) AS\nSELECT\n    time_bucket('1 hour', time) AS hour,\n    station_id,\n    AVG(temp_out) as avg_temp,\n    MIN(temp_out) as min_temp,\n    MAX(temp_out) as max_temp,\n    STDDEV(temp_out) as stddev_temp\nFROM observations\nGROUP BY hour, station_id;\n\n-- Refresh policy\nSELECT add_continuous_aggregate_policy('hourly_stats',\n    start_offset =&gt; INTERVAL '2 hours',\n    end_offset =&gt; INTERVAL '1 hour',\n    schedule_interval =&gt; INTERVAL '1 hour');\n</code></pre>"},{"location":"setup/database/#migration-from-sqlite-to-timescaledb","title":"Migration from SQLite to TimescaleDB","text":""},{"location":"setup/database/#step-1-export-data","title":"Step 1: Export Data","text":"<pre><code># Export SQLite to CSV\nsqlite3 weather_stream.db &lt;&lt;EOF\n.headers on\n.mode csv\n.output observations.csv\nSELECT * FROM observations ORDER BY time;\nEOF\n</code></pre>"},{"location":"setup/database/#step-2-import-to-timescaledb","title":"Step 2: Import to TimescaleDB","text":"<pre><code># Import CSV\npsql -d weather_monitoring -c \"\\\nCOPY observations (time, station_id, temp_out, out_hum, wind_speed, bar, rain)\nFROM '/path/to/observations.csv'\nWITH (FORMAT csv, HEADER true);\"\n</code></pre>"},{"location":"setup/database/#step-3-update-configuration","title":"Step 3: Update Configuration","text":"<pre><code># Update connection string\nDATABASE_URL = \"postgresql://postgres:password@localhost:5432/weather_monitoring\"\n</code></pre>"},{"location":"setup/database/#step-4-verify","title":"Step 4: Verify","text":"<pre><code>-- Check row count\nSELECT COUNT(*) FROM observations;\n\n-- Check time range\nSELECT MIN(time), MAX(time) FROM observations;\n\n-- Check stations\nSELECT station_id, COUNT(*) as obs_count\nFROM observations\nGROUP BY station_id\nORDER BY obs_count DESC;\n</code></pre>"},{"location":"setup/database/#performance-comparison","title":"Performance Comparison","text":"Metric SQLite TimescaleDB Insert Rate ~1000/sec ~50,000/sec Query Time (6h window) 50-100ms 10-30ms Storage (1 year, 14 stations) ~500MB ~150MB (compressed) Concurrent Reads Limited Unlimited Scalability 100 stations 10,000+ stations Setup Complexity None Medium"},{"location":"setup/database/#backup-strategies","title":"Backup Strategies","text":""},{"location":"setup/database/#sqlite-backup","title":"SQLite Backup","text":"<pre><code># Online backup\nsqlite3 weather_stream.db \".backup backup.db\"\n\n# Point-in-time backup with WAL\ncp weather_stream.db weather_stream.db.backup\ncp weather_stream.db-wal weather_stream.db-wal.backup\n</code></pre>"},{"location":"setup/database/#timescaledb-backup","title":"TimescaleDB Backup","text":"<pre><code># Logical backup\npg_dump weather_monitoring &gt; backup.sql\n\n# Physical backup (faster)\npg_basebackup -D /backups/weather -Ft -z -Xs -P\n\n# Point-in-time recovery setup\n# Edit postgresql.conf:\n# wal_level = replica\n# archive_mode = on\n# archive_command = 'cp %p /archive/%f'\n</code></pre>"},{"location":"setup/database/#high-availability","title":"High Availability","text":""},{"location":"setup/database/#timescaledb-replication","title":"TimescaleDB Replication","text":"<pre><code>-- Primary server\n-- Edit postgresql.conf\nwal_level = replica\nmax_wal_senders = 3\n\n-- Create replication user\nCREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'password';\n\n-- Standby server\npg_basebackup -h primary -D /var/lib/postgresql/data -U replicator -P -Xs -R\n</code></pre>"},{"location":"setup/database/#load-balancing","title":"Load Balancing","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   HAProxy   \u2502  (Port 5432)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n   \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n   \u2502       \u2502\n \u250c\u2500\u25bc\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2510\n \u2502 M  \u2502 \u2502 R1 \u2502  (M = Master, R = Replica)\n \u2514\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2518\n          \u2502\n        \u250c\u2500\u25bc\u2500\u2500\u2510\n        \u2502 R2 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"setup/database/#monitoring-queries","title":"Monitoring Queries","text":""},{"location":"setup/database/#sqlite","title":"SQLite","text":"<pre><code>-- Database size\nSELECT page_count * page_size / 1024.0 / 1024.0 as size_mb\nFROM pragma_page_count(), pragma_page_size();\n\n-- Recent activity\nSELECT\n    COUNT(*) as total_rows,\n    MIN(time) as oldest,\n    MAX(time) as newest,\n    COUNT(DISTINCT station_id) as stations\nFROM observations;\n</code></pre>"},{"location":"setup/database/#timescaledb","title":"TimescaleDB","text":"<pre><code>-- Hypertable stats\nSELECT * FROM timescaledb_information.hypertables;\n\n-- Chunk statistics\nSELECT\n    chunk_name,\n    range_start,\n    range_end,\n    pg_size_pretty(total_bytes) as size\nFROM timescaledb_information.chunks\nWHERE hypertable_name = 'observations'\nORDER BY range_start DESC\nLIMIT 10;\n\n-- Compression stats\nSELECT\n    pg_size_pretty(before_compression_total_bytes) as uncompressed,\n    pg_size_pretty(after_compression_total_bytes) as compressed,\n    ROUND(100 - (after_compression_total_bytes::NUMERIC / before_compression_total_bytes * 100), 2) as compression_ratio\nFROM timescaledb_information.compression_settings\nWHERE hypertable_name = 'observations';\n</code></pre> <p>For production deployment recommendations, see Deployment Guide.</p>"},{"location":"setup/deployment/","title":"Deployment","text":""},{"location":"setup/deployment/#overview","title":"Overview","text":"<p>This guide covers deploying the Real-Time Anomaly Detection system in production environments.</p>"},{"location":"setup/deployment/#deployment-options","title":"Deployment Options","text":""},{"location":"setup/deployment/#option-1-systemd-service-recommended-for-linux","title":"Option 1: Systemd Service (Recommended for Linux)","text":""},{"location":"setup/deployment/#option-2-docker-container","title":"Option 2: Docker Container","text":""},{"location":"setup/deployment/#option-3-cron-jobs","title":"Option 3: Cron Jobs","text":""},{"location":"setup/deployment/#option-4-kubernetes-enterprise","title":"Option 4: Kubernetes (Enterprise)","text":""},{"location":"setup/deployment/#option-1-systemd-service","title":"Option 1: Systemd Service","text":""},{"location":"setup/deployment/#step-1-create-service-user","title":"Step 1: Create Service User","text":"<pre><code># Create dedicated user\nsudo useradd -r -s /bin/false -m -d /var/lib/weather weather\n\n# Create directories\nsudo mkdir -p /var/lib/weather/data\nsudo mkdir -p /var/log/weather\nsudo chown -R weather:weather /var/lib/weather /var/log/weather\n</code></pre>"},{"location":"setup/deployment/#step-2-install-application","title":"Step 2: Install Application","text":"<pre><code># Clone repository\nsudo -u weather git clone https://github.com/datagems-eosc/real-time-anomaly-detection.git /var/lib/weather/app\ncd /var/lib/weather/app/stream_detection\n\n# Install dependencies in virtual environment\nsudo -u weather python3 -m venv /var/lib/weather/venv\nsudo -u weather /var/lib/weather/venv/bin/pip install -r requirements.txt\n</code></pre>"},{"location":"setup/deployment/#step-3-create-systemd-service-files","title":"Step 3: Create Systemd Service Files","text":""},{"location":"setup/deployment/#collector-service","title":"Collector Service","text":"<pre><code>sudo nano /etc/systemd/system/weather-collector.service\n</code></pre> <pre><code>[Unit]\nDescription=Weather Data Collector\nAfter=network.target\n\n[Service]\nType=simple\nUser=weather\nGroup=weather\nWorkingDirectory=/var/lib/weather/app/stream_detection\nEnvironment=\"PATH=/var/lib/weather/venv/bin\"\nEnvironment=\"WEATHER_DB=/var/lib/weather/data/weather_stream.db\"\nExecStart=/var/lib/weather/venv/bin/python streaming_collector_sqlite.py\nRestart=always\nRestartSec=30\n\n# Logging\nStandardOutput=append:/var/log/weather/collector.log\nStandardError=append:/var/log/weather/collector.error.log\n\n# Security\nNoNewPrivileges=true\nPrivateTmp=true\nProtectSystem=strict\nReadWritePaths=/var/lib/weather /var/log/weather\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"setup/deployment/#detection-service-periodic","title":"Detection Service (Periodic)","text":"<pre><code>sudo nano /etc/systemd/system/weather-detector.service\n</code></pre> <pre><code>[Unit]\nDescription=Weather Anomaly Detection\nAfter=network.target weather-collector.service\n\n[Service]\nType=oneshot\nUser=weather\nGroup=weather\nWorkingDirectory=/var/lib/weather/app/stream_detection\nEnvironment=\"PATH=/var/lib/weather/venv/bin\"\nEnvironment=\"WEATHER_DB=/var/lib/weather/data/weather_stream.db\"\nExecStart=/var/lib/weather/venv/bin/python anomaly_detector.py --end \"NOW\" --spatial-verify --save /var/log/weather/reports/report_%Y%m%d_%H%M%S.json\n\n# Logging\nStandardOutput=append:/var/log/weather/detector.log\nStandardError=append:/var/log/weather/detector.error.log\n</code></pre>"},{"location":"setup/deployment/#detection-timer","title":"Detection Timer","text":"<pre><code>sudo nano /etc/systemd/system/weather-detector.timer\n</code></pre> <pre><code>[Unit]\nDescription=Run Weather Anomaly Detection Hourly\n\n[Timer]\nOnBootSec=15min\nOnUnitActiveSec=1h\nPersistent=true\n\n[Install]\nWantedBy=timers.target\n</code></pre>"},{"location":"setup/deployment/#step-4-enable-and-start-services","title":"Step 4: Enable and Start Services","text":"<pre><code># Reload systemd\nsudo systemctl daemon-reload\n\n# Enable services\nsudo systemctl enable weather-collector.service\nsudo systemctl enable weather-detector.timer\n\n# Start services\nsudo systemctl start weather-collector.service\nsudo systemctl start weather-detector.timer\n\n# Check status\nsudo systemctl status weather-collector.service\nsudo systemctl status weather-detector.timer\n</code></pre>"},{"location":"setup/deployment/#step-5-verify-deployment","title":"Step 5: Verify Deployment","text":"<pre><code># Check collector logs\nsudo tail -f /var/log/weather/collector.log\n\n# Check database\nsudo -u weather sqlite3 /var/lib/weather/data/weather_stream.db \"SELECT COUNT(*) FROM observations;\"\n\n# Manual detection test\nsudo -u weather /var/lib/weather/venv/bin/python /var/lib/weather/app/stream_detection/anomaly_detector.py --end \"NOW\"\n</code></pre>"},{"location":"setup/deployment/#option-2-docker-container_1","title":"Option 2: Docker Container","text":""},{"location":"setup/deployment/#dockerfile","title":"Dockerfile","text":"<pre><code># Dockerfile\nFROM python:3.10-slim\n\n# Install dependencies\nRUN apt-update &amp;&amp; apt-get install -y \\\n    sqlite3 \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create app directory\nWORKDIR /app\n\n# Copy requirements\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application\nCOPY . .\n\n# Create data directory\nRUN mkdir -p /data\nVOLUME [\"/data\"]\n\n# Expose ports (if REST API is added)\n# EXPOSE 8000\n\n# Default command\nCMD [\"python\", \"streaming_collector_sqlite.py\"]\n</code></pre>"},{"location":"setup/deployment/#docker-compose","title":"Docker Compose","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  collector:\n    build: .\n    container_name: weather-collector\n    restart: always\n    volumes:\n      - weather-data:/data\n    environment:\n      - WEATHER_DB=/data/weather_stream.db\n    command: python streaming_collector_sqlite.py\n\n  detector:\n    build: .\n    container_name: weather-detector\n    restart: \"no\"\n    volumes:\n      - weather-data:/data\n      - ./reports:/reports\n    environment:\n      - WEATHER_DB=/data/weather_stream.db\n    command: python anomaly_detector.py --end \"NOW\" --spatial-verify --save /reports/report.json\n    depends_on:\n      - collector\n\nvolumes:\n  weather-data:\n</code></pre>"},{"location":"setup/deployment/#deploy-with-docker","title":"Deploy with Docker","text":"<pre><code># Build image\ndocker-compose build\n\n# Start collector\ndocker-compose up -d collector\n\n# Run detection manually\ndocker-compose run --rm detector\n\n# Or schedule with cron\necho \"0 * * * * cd /path/to/app &amp;&amp; docker-compose run --rm detector\" | crontab -\n</code></pre>"},{"location":"setup/deployment/#option-3-cron-jobs_1","title":"Option 3: Cron Jobs","text":""},{"location":"setup/deployment/#setup","title":"Setup","text":"<pre><code># Edit crontab\ncrontab -e\n\n# Add these lines:\n\n# Data collection (continuous background process)\n@reboot cd /path/to/stream_detection &amp;&amp; ./manage_collector.sh start\n\n# Anomaly detection (every hour)\n0 * * * * cd /path/to/stream_detection &amp;&amp; /path/to/venv/bin/python anomaly_detector.py --end \"NOW\" --spatial-verify &gt;&gt; /var/log/weather/detector.log 2&gt;&amp;1\n\n# Report cleanup (daily at 2 AM)\n0 2 * * * find /var/log/weather/reports -name \"*.json\" -mtime +30 -delete\n\n# Database vacuum (weekly on Sunday at 3 AM)\n0 3 * * 0 sqlite3 /var/lib/weather/weather_stream.db 'VACUUM;'\n</code></pre>"},{"location":"setup/deployment/#option-4-kubernetes","title":"Option 4: Kubernetes","text":""},{"location":"setup/deployment/#configmap","title":"ConfigMap","text":"<pre><code># configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: weather-config\ndata:\n  WEATHER_DB: \"/data/weather_stream.db\"\n  DETECTION_METHOD: \"arima\"\n  SPATIAL_VERIFY: \"1\"\n</code></pre>"},{"location":"setup/deployment/#persistentvolume","title":"PersistentVolume","text":"<pre><code># pvc.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: weather-data-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n</code></pre>"},{"location":"setup/deployment/#collector-deployment","title":"Collector Deployment","text":"<pre><code># collector-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: weather-collector\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: weather-collector\n  template:\n    metadata:\n      labels:\n        app: weather-collector\n    spec:\n      containers:\n      - name: collector\n        image: datagem/weather-collector:latest\n        envFrom:\n        - configMapRef:\n            name: weather-config\n        volumeMounts:\n        - name: data\n          mountPath: /data\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: weather-data-pvc\n</code></pre>"},{"location":"setup/deployment/#detector-cronjob","title":"Detector CronJob","text":"<pre><code># detector-cronjob.yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: weather-detector\nspec:\n  schedule: \"0 * * * *\"  # Every hour\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: detector\n            image: datagem/weather-detector:latest\n            args: [\"--end\", \"NOW\", \"--spatial-verify\"]\n            envFrom:\n            - configMapRef:\n                name: weather-config\n            volumeMounts:\n            - name: data\n              mountPath: /data\n          restartPolicy: OnFailure\n          volumes:\n          - name: data\n            persistentVolumeClaim:\n              claimName: weather-data-pvc\n</code></pre>"},{"location":"setup/deployment/#deploy-to-kubernetes","title":"Deploy to Kubernetes","text":"<pre><code>kubectl apply -f configmap.yaml\nkubectl apply -f pvc.yaml\nkubectl apply -f collector-deployment.yaml\nkubectl apply -f detector-cronjob.yaml\n\n# Check status\nkubectl get pods\nkubectl logs -f deployment/weather-collector\n</code></pre>"},{"location":"setup/deployment/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":""},{"location":"setup/deployment/#health-checks","title":"Health Checks","text":"<pre><code># /usr/local/bin/weather-healthcheck.sh\n#!/bin/bash\n\n# Check if collector is running\nif ! systemctl is-active --quiet weather-collector; then\n    echo \"ERROR: Collector not running\"\n    exit 1\nfi\n\n# Check data freshness\nLAST_DATA=$(sqlite3 /var/lib/weather/data/weather_stream.db \\\n    \"SELECT MAX(time) FROM observations;\")\nCURRENT_TIME=$(date +%s)\nLAST_DATA_TIME=$(date -d \"$LAST_DATA\" +%s 2&gt;/dev/null || echo 0)\nAGE=$((CURRENT_TIME - LAST_DATA_TIME))\n\nif [ $AGE -gt 900 ]; then  # 15 minutes\n    echo \"ERROR: Data is stale (last: $LAST_DATA)\"\n    exit 1\nfi\n\necho \"OK: System healthy\"\nexit 0\n</code></pre>"},{"location":"setup/deployment/#prometheus-metrics-future","title":"Prometheus Metrics (Future)","text":"<pre><code># metrics_exporter.py\nfrom prometheus_client import start_http_server, Gauge\nimport time\n\n# Define metrics\ndata_age = Gauge('weather_data_age_seconds', 'Age of last observation')\ndb_size = Gauge('weather_db_size_bytes', 'Database size')\ncollection_errors = Gauge('weather_collection_errors_total', 'Collection errors')\n\n# Start server\nstart_http_server(9090)\n\n# Update loop\nwhile True:\n    update_metrics()\n    time.sleep(60)\n</code></pre>"},{"location":"setup/deployment/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Import <code>grafana-dashboard.json</code> for visualization:</p> <ul> <li>Data collection rate</li> <li>Detection frequency</li> <li>Anomaly trends</li> <li>System health</li> </ul>"},{"location":"setup/deployment/#backup-recovery","title":"Backup &amp; Recovery","text":""},{"location":"setup/deployment/#automated-backup","title":"Automated Backup","text":"<pre><code>#!/bin/bash\n# /usr/local/bin/weather-backup.sh\n\nBACKUP_DIR=\"/var/backups/weather\"\nDB_PATH=\"/var/lib/weather/data/weather_stream.db\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\n\n# Create backup\nmkdir -p \"$BACKUP_DIR\"\nsqlite3 \"$DB_PATH\" \".backup '$BACKUP_DIR/weather_$TIMESTAMP.db'\"\n\n# Compress\ngzip \"$BACKUP_DIR/weather_$TIMESTAMP.db\"\n\n# Delete old backups (keep 7 days)\nfind \"$BACKUP_DIR\" -name \"weather_*.db.gz\" -mtime +7 -delete\n</code></pre> <p>Add to cron:</p> <pre><code>0 4 * * * /usr/local/bin/weather-backup.sh\n</code></pre>"},{"location":"setup/deployment/#recovery","title":"Recovery","text":"<pre><code># Restore from backup\ngunzip /var/backups/weather/weather_20251122_040000.db.gz\ncp /var/backups/weather/weather_20251122_040000.db /var/lib/weather/data/weather_stream.db\nsudo systemctl restart weather-collector\n</code></pre>"},{"location":"setup/deployment/#troubleshooting-deployment","title":"Troubleshooting Deployment","text":""},{"location":"setup/deployment/#issue-collector-not-starting","title":"Issue: Collector Not Starting","text":"<pre><code># Check logs\nsudo journalctl -u weather-collector -n 50\n\n# Check permissions\nsudo -u weather ls -l /var/lib/weather/data\n\n# Test manually\nsudo -u weather /var/lib/weather/venv/bin/python /var/lib/weather/app/stream_detection/streaming_collector_sqlite.py\n</code></pre>"},{"location":"setup/deployment/#issue-detection-fails","title":"Issue: Detection Fails","text":"<pre><code># Check if enough data\nsqlite3 /var/lib/weather/data/weather_stream.db \\\n    \"SELECT COUNT(DISTINCT time) FROM observations WHERE time &gt; datetime('now', '-6 hours');\"\n\n# Should be &gt;= 36 for 6-hour window\n\n# Run with verbose output\nsudo -u weather /var/lib/weather/venv/bin/python /var/lib/weather/app/stream_detection/anomaly_detector.py --end \"NOW\" --verbose\n</code></pre>"},{"location":"setup/deployment/#issue-high-memory-usage","title":"Issue: High Memory Usage","text":"<pre><code># Check process memory\nps aux | grep python\n\n# Reduce window size or use faster method\npython anomaly_detector.py --window 3 --temporal-method 3sigma\n</code></pre>"},{"location":"setup/deployment/#security-hardening","title":"Security Hardening","text":"<ol> <li>Run as non-root user \u2713</li> <li>Use virtual environment \u2713</li> <li>Restrict file permissions: <code>chmod 600 weather_stream.db</code></li> <li>Enable firewall: No inbound ports needed</li> <li>Regular updates: <code>pip install --upgrade -r requirements.txt</code></li> <li>Audit logs: Monitor <code>/var/log/weather/</code></li> </ol> <p>For database migration to TimescaleDB, see Database Options.</p>"},{"location":"setup/installation/","title":"Installation","text":""},{"location":"setup/installation/#prerequisites","title":"Prerequisites","text":""},{"location":"setup/installation/#system-requirements","title":"System Requirements","text":"Component Minimum Recommended OS Linux/macOS Linux (Ubuntu 20.04+) Python 3.8+ 3.10+ RAM 512MB 2GB Disk 1GB 10GB CPU 1 core 2+ cores"},{"location":"setup/installation/#software-dependencies","title":"Software Dependencies","text":"<ul> <li>Python 3.8 or higher</li> <li>pip (Python package manager)</li> <li>SQLite 3 (included with Python)</li> <li>Git (for cloning repository)</li> </ul>"},{"location":"setup/installation/#quick-start","title":"Quick Start","text":""},{"location":"setup/installation/#1-clone-repository","title":"1. Clone Repository","text":"<pre><code>git clone https://github.com/datagems-eosc/real-time-anomaly-detection.git\ncd real-time-anomaly-detection/stream_detection\n</code></pre>"},{"location":"setup/installation/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code># Using venv\npython3 -m venv venv\nsource venv/bin/activate\n\n# Or using conda\nconda create -n datagem python=3.10\nconda activate datagem\n</code></pre>"},{"location":"setup/installation/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"setup/installation/#4-verify-installation","title":"4. Verify Installation","text":"<pre><code>python anomaly_detector.py --help\n</code></pre> <p>Expected output:</p> <pre><code>usage: anomaly_detector.py [-h] [--end END] [--window WINDOW] ...\n\nReal-Time Weather Anomaly Detection System\n...\n</code></pre>"},{"location":"setup/installation/#5-test-data-collection","title":"5. Test Data Collection","text":"<pre><code># Start data collector (background)\n./manage_collector.sh start\n\n# Wait 30 seconds for first data fetch\nsleep 30\n\n# Check database\nsqlite3 weather_stream.db \"SELECT COUNT(*) FROM observations;\"\n</code></pre> <p>Expected: Number &gt; 0 (should have data from ~14 stations)</p>"},{"location":"setup/installation/#6-run-first-detection","title":"6. Run First Detection","text":"<pre><code>python anomaly_detector.py --end \"NOW\" --spatial-verify\n</code></pre> <p>If no data yet:</p> <pre><code># Wait for more data collection\nsleep 600  # 10 minutes\n\n# Try again\npython anomaly_detector.py --end \"NOW\" --spatial-verify\n</code></pre>"},{"location":"setup/installation/#detailed-installation","title":"Detailed Installation","text":""},{"location":"setup/installation/#python-environment-setup","title":"Python Environment Setup","text":""},{"location":"setup/installation/#conda-recommended","title":"Conda (Recommended)","text":"<pre><code># Create environment with specific Python version\nconda create -n datagem python=3.10\n\n# Activate\nconda activate datagem\n\n# Install pip dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"setup/installation/#installing-dependencies","title":"Installing Dependencies","text":""},{"location":"setup/installation/#from-requirementstxt","title":"From requirements.txt","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"setup/installation/#manual-installation","title":"Manual Installation","text":"<pre><code># Core dependencies\npip install pandas numpy\n\n# Time series analysis\npip install statsmodels\n\n# Machine learning\npip install scikit-learn\n\n# Visualization\npip install folium\n\n# Database (optional, for TimescaleDB)\npip install psycopg2-binary\n</code></pre>"},{"location":"setup/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>python3 &lt;&lt; EOF\nimport pandas\nimport numpy\nimport statsmodels\nimport sklearn\nimport folium\nprint(\"All dependencies installed successfully!\")\nEOF\n</code></pre>"},{"location":"setup/installation/#verifying-installation","title":"Verifying Installation","text":""},{"location":"setup/installation/#manual-verification","title":"Manual Verification","text":"<pre><code># 1. Check Python version\npython --version\n# Should be 3.8 or higher\n\n# 2. Check dependencies\npip list | grep -E '(pandas|statsmodels|scikit-learn)'\n\n# 3. Test database access\npython &lt;&lt; EOF\nimport sqlite3\nconn = sqlite3.connect('weather_stream.db')\nprint(\"Database access OK\")\nconn.close()\nEOF\n\n# 4. Test data collection\npython streaming_collector_sqlite.py --test\n\n# 5. Test detection (requires data)\npython anomaly_detector.py --end \"NOW\" --temporal-method 3sigma\n</code></pre>"},{"location":"setup/installation/#directory-structure","title":"Directory Structure","text":"<p>After installation:</p> <pre><code>stream_detection/\n\u251c\u2500\u2500 anomaly_detector.py           # Main detection script\n\u251c\u2500\u2500 streaming_collector_sqlite.py # Data collector\n\u251c\u2500\u2500 manage_collector.sh            # Service management\n\u251c\u2500\u2500 requirements.txt               # Python dependencies\n\u251c\u2500\u2500 weather_stream.db              # SQLite database (created on first run)\n\u251c\u2500\u2500 spatial_network_map.html       # Station map (optional)\n\u251c\u2500\u2500 docs/                          # Documentation (if using MkDocs)\n\u2514\u2500\u2500 README.md                      # Original README\n</code></pre>"},{"location":"setup/installation/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>Configure the system: See Configuration</li> <li>Deploy the collector: See Deployment</li> <li>Set up monitoring: See monitoring documentation (coming soon)</li> <li>Read API documentation: See API Overview</li> </ol>"},{"location":"system/architecture/","title":"System Architecture","text":""},{"location":"system/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Data Sources\"\n        A[NOA API&lt;br/&gt;GeoJSON Feed]\n    end\n\n    subgraph \"Data Layer\"\n        B[Streaming Collector&lt;br/&gt;Python Daemon]\n        C[(SQLite/&lt;br/&gt;TimescaleDB)]\n    end\n\n    subgraph \"Detection Engine\"\n        D[Anomaly Detector]\n        E[Temporal Analysis&lt;br/&gt;ARIMA/3-Sigma/MAD/etc]\n        F[Spatial Verification&lt;br/&gt;Correlation Analysis]\n    end\n\n    subgraph \"Output\"\n        G[Console Report]\n        H[JSON Export]\n        I[Visualization Maps]\n    end\n\n    A --&gt;|Every 10min| B\n    B --&gt;|Store| C\n    C --&gt;|Query Window| D\n    D --&gt; E\n    E --&gt;|Suspects| F\n    F --&gt; G\n    F --&gt; H\n    F --&gt; I</code></pre>"},{"location":"system/architecture/#component-details","title":"Component Details","text":""},{"location":"system/architecture/#1-data-collection-layer","title":"1. Data Collection Layer","text":""},{"location":"system/architecture/#streaming-collector-streaming_collector_sqlitepy","title":"Streaming Collector (<code>streaming_collector_sqlite.py</code>)","text":"<p>Purpose: Continuously fetch and store meteorological data from NOA API.</p> <p>Key Features:</p> <ul> <li>Runs as a background daemon (systemd service compatible)</li> <li>Fetches data every 10 minutes</li> <li>Handles network failures gracefully with retry logic</li> <li>Parses GeoJSON format from NOA API</li> <li>Stores data with timestamp normalization</li> </ul> <p>Architecture Pattern: Pull-based streaming</p> <pre><code># Pseudo-code\nwhile True:\n    try:\n        data = fetch_geojson(NOA_API_URL)\n        observations = parse_geojson(data)\n        store_to_database(observations)\n        log_success()\n        sleep(600)  # 10 minutes\n    except Exception as e:\n        log_error(e)\n        sleep(60)   # Retry in 1 minute\n</code></pre> <p>Management:</p> <pre><code># Start collector\n./manage_collector.sh start\n\n# Stop collector\n./manage_collector.sh stop\n\n# Check status\n./manage_collector.sh status\n</code></pre>"},{"location":"system/architecture/#2-storage-layer","title":"2. Storage Layer","text":""},{"location":"system/architecture/#database-schema","title":"Database Schema","text":"<p>The system uses a single optimized table for time-series storage:</p> <pre><code>CREATE TABLE observations (\n    time TIMESTAMP NOT NULL,\n    station_id TEXT NOT NULL,\n    temp_out REAL,\n    out_hum REAL,\n    wind_speed REAL,\n    bar REAL,\n    rain REAL,\n    PRIMARY KEY (time, station_id)\n);\n\n-- Performance index\nCREATE INDEX idx_time ON observations(time DESC);\nCREATE INDEX idx_station_time ON observations(station_id, time DESC);\n</code></pre>"},{"location":"system/architecture/#storage-options","title":"Storage Options","text":"SQLite (Default)TimescaleDB (Enterprise) <p>Use Case: Standalone deployment, development, testing</p> <p>Advantages:</p> <ul> <li>No external dependencies</li> <li>Single-file database</li> <li>Zero configuration</li> <li>Embedded in Python</li> </ul> <p>Limitations:</p> <ul> <li>Single-writer (but sufficient for this use case)</li> <li>File-based (local disk only)</li> </ul> <p>Performance:</p> <ul> <li>Query Time: &lt; 100ms for 6-hour window</li> <li>Storage: ~10MB per month (14 stations)</li> <li>Max Scale: ~100 stations</li> </ul> <p>Use Case: Production deployment, multiple collectors, advanced analytics</p> <p>Advantages:</p> <ul> <li>Automatic time-based partitioning (hypertables)</li> <li>Distributed queries</li> <li>Advanced compression</li> <li>Continuous aggregates</li> </ul> <p>Configuration:</p> <pre><code>-- Convert table to hypertable\nSELECT create_hypertable('observations', 'time');\n\n-- Enable compression (optional)\nALTER TABLE observations SET (\n    timescaledb.compress,\n    timescaledb.compress_segmentby = 'station_id'\n);\n</code></pre> <p>Performance:</p> <ul> <li>Query Time: &lt; 50ms for 6-hour window</li> <li>Storage: ~3MB per month with compression</li> <li>Max Scale: 10,000+ stations</li> </ul>"},{"location":"system/architecture/#3-detection-engine","title":"3. Detection Engine","text":""},{"location":"system/architecture/#main-detector-anomaly_detectorpy","title":"Main Detector (<code>anomaly_detector.py</code>)","text":"<p>Purpose: Orchestrates temporal detection and spatial verification.</p> <p>Workflow:</p> <pre><code>class AnomalyDetector:\n    def detect(self, end_time, window_hours, method, spatial_verify):\n        # 1. Query data window\n        data = self.query_window(end_time, window_hours)\n\n        # 2. Temporal detection for each station\n        suspects = []\n        for station in self.stations:\n            if self.temporal_detector.is_anomalous(station, data):\n                suspects.append(station)\n\n        # 3. Spatial verification (if enabled)\n        if spatial_verify:\n            for suspect in suspects:\n                neighbors = self.find_neighbors(suspect)\n                correlation = self.compute_correlation(suspect, neighbors)\n                classification = self.classify(correlation)\n                suspect.classification = classification\n\n        # 4. Generate report\n        return self.generate_report(suspects)\n</code></pre>"},{"location":"system/architecture/#temporal-detectors","title":"Temporal Detectors","text":"<p>Each detection method implements a common interface:</p> <pre><code>class TemporalDetector:\n    def is_anomalous(self, station_data, variable):\n        \"\"\"\n        Returns True if the latest value is anomalous.\n        \"\"\"\n        pass\n</code></pre> <p>Supported Methods:</p> Method Implementation Threshold ARIMA <code>statsmodels.tsa.arima.model.ARIMA</code> Forecast confidence interval 3-Sigma Z-score: <code>(x - \u03bc) / \u03c3 &gt; 3</code> 3 standard deviations MAD <code>abs(x - median) / MAD &gt; 3.5</code> 3.5 MAD units IQR <code>x &lt; Q1 - 1.5*IQR or x &gt; Q3 + 1.5*IQR</code> 1.5 IQR Isolation Forest <code>sklearn.ensemble.IsolationForest</code> Contamination = 0.1 STL Seasonal decomposition residuals 3 sigma on residuals LOF <code>sklearn.neighbors.LocalOutlierFactor</code> Negative outlier factor"},{"location":"system/architecture/#spatial-verifier","title":"Spatial Verifier","text":"<p>Purpose: Compare suspect station with neighbors to classify anomaly type.</p> <p>Algorithm:</p> <pre><code>def verify_spatial(suspect_station, window_hours):\n    # 1. Find neighbors within 100km\n    neighbors = find_neighbors(suspect_station, radius_km=100)\n\n    # 2. Get time series for all\n    suspect_series = get_series(suspect_station, window_hours)\n    neighbor_series = [get_series(n, window_hours) for n in neighbors]\n\n    # 3. Interpolate missing values\n    suspect_series = interpolate(suspect_series)\n    neighbor_series = [interpolate(s) for s in neighbor_series]\n\n    # 4. Calculate Pearson correlation\n    correlations = [pearson(suspect_series, ns) for ns in neighbor_series]\n    avg_correlation = mean(correlations)\n\n    # 5. Classify\n    if avg_correlation &gt; 0.6:\n        return \"weather_event\"\n    elif avg_correlation &lt; 0.3:\n        return \"device_failure\"\n    else:\n        return \"suspected\"\n</code></pre> <p>Interpolation Strategy:</p> <p>When neighbor data has missing values:</p> <pre><code># Linear interpolation for small gaps (&lt; 3 consecutive points)\nseries.interpolate(method='linear', limit=3, inplace=True)\n\n# Forward fill for remaining gaps\nseries.fillna(method='ffill', inplace=True)\n</code></pre>"},{"location":"system/architecture/#4-output-layer","title":"4. Output Layer","text":""},{"location":"system/architecture/#console-reporter","title":"Console Reporter","text":"<p>Generates human-readable reports with:</p> <ul> <li>Summary statistics</li> <li>Detailed anomaly descriptions</li> <li>Spatial verification diagnostics</li> <li>Data tables for manual inspection</li> </ul>"},{"location":"system/architecture/#json-exporter","title":"JSON Exporter","text":"<p>Produces structured output for:</p> <ul> <li>Integration with monitoring systems</li> <li>Historical analysis</li> <li>Dashboard visualization</li> </ul>"},{"location":"system/architecture/#map-generator-generate_mappy","title":"Map Generator (<code>generate_map.py</code>)","text":"<p>Creates interactive HTML maps using Folium:</p> <ul> <li>Station locations</li> <li>Neighbor connections (red lines)</li> <li>Metadata tooltips</li> </ul>"},{"location":"system/architecture/#deployment-pattern","title":"Deployment Pattern","text":""},{"location":"system/architecture/#standalone-server","title":"Standalone Server","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Single Server         \u2502\n\u2502                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Collector       \u2502   \u2502\n\u2502  \u2502 (Background)    \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502          \u2193              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 SQLite DB       \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502          \u2193              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Detector        \u2502   \u2502\n\u2502  \u2502 (On-demand)     \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Use Case: Current implementation for NOA meteorological stations</p>"},{"location":"system/architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"system/architecture/#data-storage","title":"Data Storage","text":"<ul> <li>Database files have restricted permissions (600)</li> <li>No sensitive user data stored</li> <li>All data is public meteorological information</li> </ul>"},{"location":"system/architecture/#network","title":"Network","text":"<ul> <li>API calls use HTTPS</li> <li>No authentication required (public API)</li> <li>Rate limiting respected (1 request per 10 minutes)</li> </ul>"},{"location":"system/architecture/#process-isolation","title":"Process Isolation","text":"<ul> <li>Collector runs as limited user</li> <li>No root privileges required</li> <li>Systemd sandboxing recommended</li> </ul>"},{"location":"system/architecture/#monitoring-and-health-checks","title":"Monitoring and Health Checks","text":""},{"location":"system/architecture/#collector-health","title":"Collector Health","text":"<p>Monitor these indicators:</p> <ul> <li>Last successful fetch timestamp</li> <li>Consecutive failure count</li> <li>Network latency to API</li> <li>Database write latency</li> </ul> <p>Example health check:</p> <pre><code># Check if collector is running\nps aux | grep streaming_collector\n\n# Check last data timestamp\nsqlite3 weather_stream.db \\\n  \"SELECT MAX(time) FROM observations;\"\n\n# Check data freshness (should be &lt; 15 minutes)\n</code></pre>"},{"location":"system/detection-methods/","title":"Detection Methods","text":""},{"location":"system/detection-methods/#temporal-detection-methods","title":"Temporal Detection Methods","text":"<p>Temporal methods analyze a single station's behavior over time to detect anomalies.</p>"},{"location":"system/detection-methods/#arima-autoregressive-integrated-moving-average","title":"ARIMA (AutoRegressive Integrated Moving Average)","text":"<p>Best For: Complex trends, seasonal patterns, weather forecasting</p> <p>How It Works:</p> <p>ARIMA models the time series as a combination of:</p> <ul> <li>AR (AutoRegressive): Current value depends on past values</li> <li>I (Integrated): Differencing to make the series stationary</li> <li>MA (Moving Average): Current value depends on past forecast errors</li> </ul> <p>Parameters: <code>(p, d, q)</code> where:</p> <ul> <li><code>p</code>: Number of lag observations</li> <li><code>d</code>: Degree of differencing</li> <li><code>q</code>: Size of moving average window</li> </ul> <p>Implementation:</p> <pre><code>from statsmodels.tsa.arima.model import ARIMA\n\n# Fit model on historical data\nmodel = ARIMA(historical_data, order=(1, 1, 1))\nfitted = model.fit()\n\n# Forecast next value\nforecast = fitted.forecast(steps=1)\nconfidence_interval = fitted.get_forecast(steps=1).conf_int()\n\n# Check if actual value is outside confidence interval\nif actual &lt; confidence_interval[0] or actual &gt; confidence_interval[1]:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Captures complex patterns</li> <li>Provides confidence intervals</li> <li>Adapts to trends</li> </ul> <p>Disadvantages:</p> <ul> <li>Computationally expensive</li> <li>Requires sufficient historical data (&gt; 30 points)</li> <li>May fail on very noisy data</li> </ul> <p>Recommended Settings:</p> <ul> <li>Window size: 6 hours (36 data points at 10-min intervals)</li> <li>Order: <code>(1, 1, 1)</code> for most weather variables</li> <li>Confidence level: 95%</li> </ul>"},{"location":"system/detection-methods/#3-sigma-z-score","title":"3-Sigma (Z-Score)","text":"<p>Best For: Quick outlier detection, normally distributed data</p> <p>How It Works:</p> <p>Calculates how many standard deviations the current value is from the mean:</p> <p>[ Z = \\frac{X - \\mu}{\\sigma} ]</p> <p>Where:</p> <ul> <li>(X) = Current value</li> <li>(\\mu) = Mean of historical data</li> <li>(\\sigma) = Standard deviation</li> </ul> <p>Implementation:</p> <pre><code>import numpy as np\n\nmean = np.mean(historical_data)\nstd = np.std(historical_data)\n\nz_score = (actual_value - mean) / std\n\nif abs(z_score) &gt; 3:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Extremely fast</li> <li>Simple to understand</li> <li>Works well for stable data</li> </ul> <p>Disadvantages:</p> <ul> <li>Assumes normal distribution</li> <li>Sensitive to outliers in historical data</li> <li>Doesn't capture trends</li> </ul> <p>Recommended Settings:</p> <ul> <li>Threshold: 3 (captures 99.7% of normal data)</li> <li>Window size: 6 hours minimum</li> </ul>"},{"location":"system/detection-methods/#mad-median-absolute-deviation","title":"MAD (Median Absolute Deviation)","text":"<p>Best For: Robust detection, data with outliers, stable baselines</p> <p>How It Works:</p> <p>Uses median instead of mean for robustness:</p> <p>[ \\text{MAD} = \\text{median}(|X_i - \\text{median}(X)|) ]</p> <p>[ \\text{Score} = \\frac{|X - \\text{median}(X)|}{\\text{MAD}} ]</p> <p>Implementation:</p> <pre><code>import numpy as np\n\nmedian = np.median(historical_data)\nmad = np.median(np.abs(historical_data - median))\n\nscore = abs(actual_value - median) / mad\n\nif score &gt; 3.5:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Robust to outliers</li> <li>No assumption of normal distribution</li> <li>Stable over time</li> </ul> <p>Disadvantages:</p> <ul> <li>Can be too sensitive to changes</li> <li>Doesn't handle trends well</li> <li>May flag all values if data is flat</li> </ul> <p>Recommended Settings:</p> <ul> <li>Threshold: 3.5</li> <li>Use when baseline is stable (e.g., barometric pressure)</li> </ul>"},{"location":"system/detection-methods/#iqr-interquartile-range","title":"IQR (Interquartile Range)","text":"<p>Best For: Exploratory analysis, boxplot-style outlier detection</p> <p>How It Works:</p> <p>Uses quartiles to define normal range:</p> <p>[ \\text{IQR} = Q_3 - Q_1 ]</p> <p>Outliers are values outside:</p> <p>[ [Q_1 - 1.5 \\times \\text{IQR}, Q_3 + 1.5 \\times \\text{IQR}] ]</p> <p>Implementation:</p> <pre><code>import numpy as np\n\nq1 = np.percentile(historical_data, 25)\nq3 = np.percentile(historical_data, 75)\niqr = q3 - q1\n\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\n\nif actual_value &lt; lower_bound or actual_value &gt; upper_bound:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Intuitive (boxplot logic)</li> <li>Robust to outliers</li> <li>No distribution assumptions</li> </ul> <p>Disadvantages:</p> <ul> <li>Static threshold</li> <li>Doesn't capture trends</li> <li>Less sensitive than other methods</li> </ul> <p>Recommended Settings:</p> <ul> <li>Multiplier: 1.5 (standard) or 3.0 (conservative)</li> </ul>"},{"location":"system/detection-methods/#isolation-forest","title":"Isolation Forest","text":"<p>Best For: Multidimensional patterns, complex anomalies</p> <p>How It Works:</p> <p>Machine learning algorithm that isolates anomalies by randomly partitioning data:</p> <ul> <li>Anomalies are easier to isolate (fewer splits needed)</li> <li>Normal points are harder to isolate (more splits needed)</li> </ul> <p>Implementation:</p> <pre><code>from sklearn.ensemble import IsolationForest\n\n# Train on historical data (all variables)\nX = historical_data[['temp_out', 'out_hum', 'wind_speed', 'bar', 'rain']]\nmodel = IsolationForest(contamination=0.1, random_state=42)\nmodel.fit(X)\n\n# Predict on current value\ncurrent = [[temp, hum, wind, bar, rain]]\nprediction = model.predict(current)\n\nif prediction[0] == -1:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Finds subtle patterns</li> <li>Handles multiple variables simultaneously</li> <li>No assumption of distribution</li> </ul> <p>Disadvantages:</p> <ul> <li>Black box (hard to interpret)</li> <li>Requires all variables present</li> <li>Sensitive to contamination parameter</li> </ul> <p>Recommended Settings:</p> <ul> <li>Contamination: 0.1 (expect 10% anomalies)</li> <li>Random state: 42 (for reproducibility)</li> </ul>"},{"location":"system/detection-methods/#stl-seasonal-trend-decomposition","title":"STL (Seasonal-Trend Decomposition)","text":"<p>Best For: Data with strong seasonality (daily/weekly cycles)</p> <p>How It Works:</p> <p>Decomposes time series into:</p> <ul> <li>Trend: Long-term progression</li> <li>Seasonal: Repeating patterns</li> <li>Residual: Remaining variation</li> </ul> <p>Anomalies are detected in the residual component.</p> <p>Implementation:</p> <pre><code>from statsmodels.tsa.seasonal import STL\n\n# Decompose time series\nstl = STL(historical_data, seasonal=13)  # 13 for 6.5-hour cycle\nresult = stl.fit()\n\n# Get residuals\nresiduals = result.resid\n\n# Detect outliers in residuals using 3-sigma\nthreshold = 3 * np.std(residuals)\nif abs(residuals[-1]) &gt; threshold:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Handles seasonality well</li> <li>Separates trend from noise</li> <li>Interpretable components</li> </ul> <p>Disadvantages:</p> <ul> <li>Requires sufficient data (&gt; 2 cycles)</li> <li>Computationally expensive</li> <li>Fixed seasonal period</li> </ul> <p>Recommended Settings:</p> <ul> <li>Seasonal period: 13 (for 2-hour cycles at 10-min intervals)</li> <li>Use for temperature (daily cycle)</li> </ul>"},{"location":"system/detection-methods/#lof-local-outlier-factor","title":"LOF (Local Outlier Factor)","text":"<p>Best For: Density-based outlier detection, clustered data</p> <p>How It Works:</p> <p>Measures local deviation of density compared to neighbors:</p> <ul> <li>High LOF: Point is in a sparse region (outlier)</li> <li>Low LOF: Point is in a dense region (normal)</li> </ul> <p>Implementation:</p> <pre><code>from sklearn.neighbors import LocalOutlierFactor\n\n# Fit on historical data\nlof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\nlof.fit(historical_data.reshape(-1, 1))\n\n# Predict on current value\nprediction = lof.fit_predict(\n    np.append(historical_data, actual_value).reshape(-1, 1)\n)\n\nif prediction[-1] == -1:\n    return True  # Anomalous\n</code></pre> <p>Advantages:</p> <ul> <li>Finds local outliers</li> <li>Handles varying densities</li> <li>No global threshold needed</li> </ul> <p>Disadvantages:</p> <ul> <li>Sensitive to k parameter</li> <li>Computationally expensive</li> <li>Requires retraining for each prediction</li> </ul> <p>Recommended Settings:</p> <ul> <li>n_neighbors: 20</li> <li>contamination: 0.1</li> </ul>"},{"location":"system/detection-methods/#spatial-verification-methods","title":"Spatial Verification Methods","text":""},{"location":"system/detection-methods/#pearson-correlation-default","title":"Pearson Correlation (Default)","text":"<p>Purpose: Measure trend consistency between suspect and neighbors</p> <p>Formula:</p> <p>[ r = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum (X_i - \\bar{X})^2 \\sum (Y_i - \\bar{Y})^2}} ]</p> <p>Where:</p> <ul> <li>(X) = Suspect station time series</li> <li>(Y) = Neighbor station time series</li> </ul> <p>Implementation:</p> <pre><code>from scipy.stats import pearsonr\n\n# Get time series for same window\nsuspect_series = get_series(suspect_station, window_hours=6)\nneighbor_series = get_series(neighbor_station, window_hours=6)\n\n# Compute correlation\ncorrelation, p_value = pearsonr(suspect_series, neighbor_series)\n\n# Classify based on correlation\nif correlation &gt; 0.6:\n    return \"weather_event\"\nelif correlation &lt; 0.3:\n    return \"device_failure\"\nelse:\n    return \"suspected\"\n</code></pre> <p>Thresholds:</p> Correlation Interpretation Action &gt; 0.6 Strong positive correlation Weather event (ignore) 0.3 to 0.6 Weak correlation Suspected (manual review) &lt; 0.3 No correlation Device failure (alert) <p>Advantages:</p> <ul> <li>Measures trend, not absolute values</li> <li>Robust to different base temperatures</li> <li>Interpretable</li> </ul> <p>Disadvantages:</p> <ul> <li>Requires sufficient data points (&gt; 10)</li> <li>Can be affected by missing data</li> <li>Assumes linear relationship</li> </ul>"},{"location":"system/detection-methods/#distance-based-fallback","title":"Distance-Based (Fallback)","text":"<p>Purpose: Static comparison when correlation fails</p> <p>How It Works:</p> <p>Compares current values directly using MAD:</p> <p>[ \\text{deviation} = \\frac{|X_{\\text{suspect}} - \\text{median}(X_{\\text{neighbors}})|}{\\text{MAD}(X_{\\text{neighbors}})} ]</p> <p>Implementation:</p> <pre><code>import numpy as np\n\n# Get current values from all neighbors\nneighbor_values = [get_current_value(n) for n in neighbors]\n\nmedian = np.median(neighbor_values)\nmad = np.median(np.abs(neighbor_values - median))\n\ndeviation = abs(suspect_value - median) / mad\n\nif deviation &gt; 3:\n    return \"device_failure\"\nelse:\n    return \"weather_event\"\n</code></pre> <p>Use Cases:</p> <ul> <li>Not enough historical data for correlation</li> <li>All neighbors have missing data</li> <li>Correlation computation fails</li> </ul>"},{"location":"system/detection-methods/#method-comparison","title":"Method Comparison","text":""},{"location":"system/detection-methods/#performance-comparison","title":"Performance Comparison","text":"Method CPU Time Memory Accuracy False Positives ARIMA High Medium \u2605\u2605\u2605\u2605\u2605 Low 3-Sigma Low Low \u2605\u2605\u2605\u2606\u2606 Medium MAD Low Low \u2605\u2605\u2605\u2605\u2606 High IQR Low Low \u2605\u2605\u2605\u2606\u2606 Medium Isolation Forest Medium Medium \u2605\u2605\u2605\u2605\u2606 Low STL High Medium \u2605\u2605\u2605\u2605\u2606 Medium LOF High High \u2605\u2605\u2605\u2606\u2606 Medium"},{"location":"system/detection-methods/#recommended-use-cases","title":"Recommended Use Cases","text":"TemperatureHumidityWind SpeedPressureRainfall <p>Primary: ARIMA (captures daily cycles)</p> <p>Backup: STL (if strong seasonality)</p> <p>Quick Check: 3-Sigma</p> <p>Primary: ARIMA</p> <p>Backup: MAD (robust to spikes)</p> <p>Quick Check: IQR</p> <p>Primary: MAD (very volatile)</p> <p>Backup: ARIMA</p> <p>Quick Check: IQR</p> <p>Primary: 3-Sigma (stable baseline)</p> <p>Backup: ARIMA</p> <p>Quick Check: MAD</p> <p>Primary: IQR (sparse data, many zeros)</p> <p>Backup: Isolation Forest</p> <p>Quick Check: Simple threshold (&gt; 100mm/h)</p>"},{"location":"system/detection-methods/#tuning-guidelines","title":"Tuning Guidelines","text":"<ol> <li>Start with ARIMA: Best overall performance</li> <li>If too slow: Switch to 3-Sigma or MAD</li> <li>If too many false positives: Lower threshold or switch to IQR</li> <li>If missing real anomalies: Increase window size or use Isolation Forest</li> <li>Always enable spatial verification: Reduces false positives by 80%</li> </ol>"},{"location":"system/station-network/","title":"Station Network","text":""},{"location":"system/station-network/#overview","title":"Overview","text":"<p>The Real-Time Anomaly Detection system monitors 14 meteorological stations operated by the National Observatory of Athens (NOA). Understanding the spatial relationships between these stations is crucial for the dual-verification strategy.</p>"},{"location":"system/station-network/#interactive-map","title":"Interactive Map","text":"<p>Open in new window</p>"},{"location":"system/station-network/#map-legend","title":"Map Legend","text":"<ul> <li>Blue Markers: Weather station locations</li> <li>Red Lines: Neighbor connections (stations within 100km)</li> <li>Hover/Click: View station details</li> </ul>"},{"location":"system/station-network/#station-details","title":"Station Details","text":""},{"location":"system/station-network/#station-list","title":"Station List","text":"Station ID Name Location Elevation Active Neighbors uth_volos University of Thessaly Volos 15m 3 volos Volos City Volos 5m 4 zagora Zagora Pelion 480m 2 pelion Pelion Mt. Pelion 1200m 1 anavra Anavra Anavra 320m 2 domokos Domokos Domokos 280m 3 karditsa Karditsa Karditsa 110m 2 larissa Larissa Larissa 75m 4 trikala Trikala Trikala 115m 3 pyli Pyli Pyli 310m 2 metsovo Metsovo Metsovo 1160m 1 ioannina Ioannina Ioannina 480m 2 agrinio Agrinio Agrinio 25m 2 preveza Preveza Preveza 5m 1 <p>Data Source</p> <p>Station metadata and real-time observations are provided by NOA via their DataGEMS GeoJSON Feed.</p>"},{"location":"system/station-network/#neighbor-selection-criteria","title":"Neighbor Selection Criteria","text":""},{"location":"system/station-network/#distance-threshold-100km","title":"Distance Threshold: 100km","text":"<p>The system uses a 100km radius to define neighbors based on:</p> <ol> <li>Weather Correlation: Meteorological phenomena typically affect regions within 50-150km</li> <li>Station Density: Balances coverage vs. computational cost</li> <li>False Positive Reduction: Sufficient neighbors for reliable correlation (typically 2-5 per station)</li> </ol>"},{"location":"system/station-network/#distance-calculation","title":"Distance Calculation","text":"<p>Haversine formula for geographic distance:</p> <pre><code>from math import radians, sin, cos, sqrt, atan2\n\ndef haversine_distance(lat1, lon1, lat2, lon2):\n    \"\"\"\n    Calculate distance between two points on Earth.\n    Returns distance in kilometers.\n    \"\"\"\n    R = 6371  # Earth's radius in km\n\n    dlat = radians(lat2 - lat1)\n    dlon = radians(lon2 - lon1)\n\n    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1-a))\n\n    return R * c\n</code></pre>"},{"location":"system/station-network/#neighbor-relationships","title":"Neighbor Relationships","text":""},{"location":"system/station-network/#example-uth_volos-station","title":"Example: uth_volos Station","text":"<p>Location: 39.3636\u00b0N, 22.9530\u00b0E</p> <p>Neighbors (within 100km):</p> Neighbor Distance Direction Typical Correlation volos 3.2 km SE &gt; 0.9 (very high) zagora 28.5 km NE &gt; 0.7 (high) larissa 62.4 km W &gt; 0.6 (moderate) <p>Use Case:</p> <p>When <code>uth_volos</code> shows an anomalous temperature drop:</p> <ol> <li>Check if <code>volos</code> (3km away) shows the same drop \u2192 If yes, likely weather</li> <li>Check if <code>zagora</code> and <code>larissa</code> also show drops \u2192 Confirms regional weather event</li> <li>If only <code>uth_volos</code> is anomalous \u2192 Likely device failure</li> </ol>"},{"location":"system/station-network/#isolated-stations","title":"Isolated Stations","text":"<p>Some stations have no neighbors within 100km:</p> <ul> <li>metsovo: High altitude, mountainous region</li> <li>preveza: Coastal, isolated location</li> </ul> <p>For these stations:</p> <ul> <li>Spatial verification is skipped</li> <li>Classification relies solely on temporal detection</li> <li>Higher false positive rate expected</li> </ul> <p>Isolated Station Behavior</p> <p>Anomalies at isolated stations are marked as \"Suspected\" rather than \"Device Failure\" because spatial verification is unavailable.</p>"},{"location":"system/station-network/#network-topology","title":"Network Topology","text":""},{"location":"system/station-network/#connectivity-graph","title":"Connectivity Graph","text":"<pre><code>graph LR\n    A[uth_volos] --- B[volos]\n    A --- C[zagora]\n    A --- D[larissa]\n\n    B --- C\n    B --- D\n    B --- E[anavra]\n\n    C --- F[pelion]\n\n    D --- G[karditsa]\n    D --- H[domokos]\n    D --- I[trikala]\n\n    I --- J[pyli]\n    I --- K[metsovo]\n\n    K --- L[ioannina]\n\n    L --- M[agrinio]\n\n    M --- N[preveza]</code></pre>"},{"location":"system/station-network/#network-statistics","title":"Network Statistics","text":"Metric Value Notes Total Stations 14 Monitored by NOA Total Connections 28 Within 100km radius Average Neighbors 4.0 Per station Max Neighbors 5 Station: larissa Min Neighbors 0 Stations: metsovo, preveza Network Diameter 6 Max hops between any two stations Clustering Coefficient 0.42 Moderate clustering"},{"location":"system/station-network/#spatial-correlation-patterns","title":"Spatial Correlation Patterns","text":""},{"location":"system/station-network/#typical-weather-event","title":"Typical Weather Event","text":"<p>When a weather front passes through:</p> <pre><code>Station A: Temp 15\u00b0C \u2192 10\u00b0C (\u21935\u00b0C)\nStation B: Temp 16\u00b0C \u2192 11\u00b0C (\u21935\u00b0C)\nStation C: Temp 14\u00b0C \u2192 9\u00b0C (\u21935\u00b0C)\n\n\u2192 Correlation: 0.95 (all drop together)\n\u2192 Classification: Weather Event\n</code></pre>"},{"location":"system/station-network/#typical-device-failure","title":"Typical Device Failure","text":"<p>When one sensor malfunctions:</p> <pre><code>Station A: Temp 15\u00b0C \u2192 99\u00b0C (sensor error)\nStation B: Temp 16\u00b0C \u2192 16\u00b0C (stable)\nStation C: Temp 14\u00b0C \u2192 14\u00b0C (stable)\n\n\u2192 Correlation: -0.05 (no pattern)\n\u2192 Classification: Device Failure\n</code></pre>"},{"location":"system/station-network/#edge-case-local-phenomenon","title":"Edge Case: Local Phenomenon","text":"<p>Microclimates can cause legitimate but isolated anomalies:</p> <pre><code>Station A (coastal): Temp 20\u00b0C \u2192 15\u00b0C (sea breeze)\nStation B (inland): Temp 22\u00b0C \u2192 22\u00b0C (stable)\nStation C (inland): Temp 21\u00b0C \u2192 21\u00b0C (stable)\n\n\u2192 Correlation: 0.35 (weak)\n\u2192 Classification: Suspected (requires manual review)\n</code></pre>"},{"location":"system/station-network/#dynamic-neighbor-selection","title":"Dynamic Neighbor Selection","text":""},{"location":"system/station-network/#current-implementation","title":"Current Implementation","text":"<p>Static: All neighbor relationships are pre-computed based on GPS coordinates.</p> <p>Advantage: Fast lookup, no runtime overhead.</p>"},{"location":"system/station-network/#future-enhancement","title":"Future Enhancement","text":"<p>Dynamic: Adjust neighbor weights based on:</p> <ol> <li>Historical Correlation: Stations that historically correlate better get higher weight</li> <li>Elevation Similarity: Stations at similar altitude may correlate better</li> <li>Wind Direction: Use upstream stations when wind data is available</li> <li>Seasonal Adjustment: Different neighbor sets for summer vs. winter</li> </ol> <p>Pseudocode:</p> <pre><code>def get_dynamic_neighbors(station, current_conditions):\n    candidates = get_all_neighbors_within_radius(station, 100)\n\n    # Weight by historical correlation\n    for n in candidates:\n        n.weight = historical_correlation(station, n)\n\n    # Adjust for elevation\n    for n in candidates:\n        elev_diff = abs(station.elevation - n.elevation)\n        if elev_diff &gt; 500:  # 500m difference\n            n.weight *= 0.5  # Reduce weight\n\n    # Adjust for wind direction (if available)\n    if current_conditions.wind_direction:\n        for n in candidates:\n            if is_upstream(n, station, current_conditions.wind_direction):\n                n.weight *= 1.5  # Increase weight\n\n    # Return top N weighted neighbors\n    return sorted(candidates, key=lambda x: x.weight, reverse=True)[:5]\n</code></pre>"},{"location":"system/station-network/#map-generation","title":"Map Generation","text":"<p>The interactive map is generated using the <code>generate_map.py</code> script:</p> <pre><code># Generate or update the station network map\npython generate_map.py\n</code></pre> <p>Output: <code>spatial_network_map.html</code></p> <p>Technology: Folium - Python wrapper for Leaflet.js</p> <p>Data Source: Station GPS coordinates from NOA API</p>"},{"location":"system/station-network/#customization","title":"Customization","text":"<p>Edit the map generation parameters in <code>generate_map.py</code>:</p> <pre><code># Configuration\nNEIGHBOR_RADIUS_KM = 100\nMAP_CENTER = [39.0, 22.0]  # Central Greece\nMAP_ZOOM = 8\nLINE_COLOR = 'red'\nLINE_WEIGHT = 2\nMARKER_COLOR = 'blue'\n</code></pre>"}]}